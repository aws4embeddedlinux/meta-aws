From cb491376ca3827e928979c41129827015ff7ef91 Mon Sep 17 00:00:00 2001
From: John Harrison <jargh@amazon.com>
Date: Wed, 1 Mar 2023 08:47:45 -0800
Subject: [PATCH] Loosen modular reductions in X25519 basepoint functions

The main loop now just maintains coordinates modulo 2^256-38,
only fully reducing modulo 2^255-19 right at the end, which
improves performance slightly.

s2n-bignum original commit: https://github.com/awslabs/s2n-bignum/commit/c8c00c8d71a999938be78cc3e8b99980b983f54a
---
 arm/curve25519/curve25519_x25519base.S        | 102 ++++++----------
 arm/curve25519/curve25519_x25519base_alt.S    | 102 ++++++----------
 x86_att/curve25519/curve25519_x25519base.S    | 114 +++++++-----------
 .../curve25519/curve25519_x25519base_alt.S    | 112 +++++++----------
 4 files changed, 168 insertions(+), 262 deletions(-)

diff --git a/arm/curve25519/curve25519_x25519base.S b/arm/curve25519/curve25519_x25519base.S
index 314169cf3..707663069 100644
--- a/arm/curve25519/curve25519_x25519base.S
+++ b/arm/curve25519/curve25519_x25519base.S
@@ -400,55 +400,6 @@
         stp     x7, x8, [P0];                   \
         stp     x9, x10, [P0+16]
 
-// Plain 4-digit add and doubling without any normalization
-// With inputs < p_25519 (indeed < 2^255) it still gives a 4-digit result,
-// indeed one < 2 * p_25519 for normalized inputs.
-
-#define add_4(P0,P1,P2)                         \
-        ldp     x0, x1, [P1];                   \
-        ldp     x4, x5, [P2];                   \
-        adds    x0, x0, x4;                     \
-        adcs    x1, x1, x5;                     \
-        ldp     x2, x3, [P1+16];                \
-        ldp     x6, x7, [P2+16];                \
-        adcs    x2, x2, x6;                     \
-        adc     x3, x3, x7;                     \
-        stp     x0, x1, [P0];                   \
-        stp     x2, x3, [P0+16]
-
-#define double_4(P0,P1)                         \
-        ldp     x0, x1, [P1];                   \
-        adds    x0, x0, x0;                     \
-        adcs    x1, x1, x1;                     \
-        ldp     x2, x3, [P1+16];                \
-        adcs    x2, x2, x2;                     \
-        adc     x3, x3, x3;                     \
-        stp     x0, x1, [P0];                   \
-        stp     x2, x3, [P0+16]
-
-// Subtraction of a pair of numbers < p_25519 just sufficient
-// to give a 4-digit result. It actually always does (x - z) + (2^255-19)
-// which in turn is done by (x - z) - (2^255+19) discarding the 2^256
-// implicitly
-
-#define sub_4(P0,P1,P2)                         \
-        ldp     x5, x6, [P1];                   \
-        ldp     x4, x3, [P2];                   \
-        subs    x5, x5, x4;                     \
-        sbcs    x6, x6, x3;                     \
-        ldp     x7, x8, [P1+16];                \
-        ldp     x4, x3, [P2+16];                \
-        sbcs    x7, x7, x4;                     \
-        sbcs    x8, x8, x3;                     \
-        mov     x3, #19;                        \
-        subs    x5, x5, x3;                     \
-        sbcs    x6, x6, xzr;                    \
-        sbcs    x7, x7, xzr;                    \
-        mov     x4, #0x8000000000000000;        \
-        sbc     x8, x8, x4;                     \
-        stp     x5, x6, [P0];                   \
-        stp     x7, x8, [P0+16]
-
 // Modular subtraction with double modulus 2 * p_25519 = 2^256 - 38
 
 #define sub_twice4(P0,P1,P2)                    \
@@ -469,8 +420,11 @@
         stp     x5, x6, [P0];                   \
         stp     x7, x8, [P0+16]
 
-// Modular addition with inputs double modulus 2 * p_25519 = 2^256 - 38
-// and in general only guaranteeing a 4-digit result, not even < 2 * p_25519.
+// Modular addition and doubling with double modulus 2 * p_25519 = 2^256 - 38.
+// This only ensures that the result fits in 4 digits, not that it is reduced
+// even w.r.t. double modulus. The result is always correct modulo provided
+// the sum of the inputs is < 2^256 + 2^256 - 38, so in particular provided
+// at least one of them is reduced double modulo.
 
 #define add_twice4(P0,P1,P2)                    \
         ldp     x3, x4, [P1];                   \
@@ -490,6 +444,22 @@
         stp     x3, x4, [P0];                   \
         stp     x5, x6, [P0+16]
 
+#define double_twice4(P0,P1)                    \
+        ldp     x3, x4, [P1];                   \
+        adds    x3, x3, x3;                     \
+        adcs    x4, x4, x4;                     \
+        ldp     x5, x6, [P1+16];                \
+        adcs    x5, x5, x5;                     \
+        adcs    x6, x6, x6;                     \
+        mov     x9, #38;                        \
+        csel    x9, x9, xzr, cs;                \
+        adds    x3, x3, x9;                     \
+        adcs    x4, x4, xzr;                    \
+        adcs    x5, x5, xzr;                    \
+        adc     x6, x6, xzr;                    \
+        stp     x3, x4, [P0];                   \
+        stp     x5, x6, [P0+16]
+
 S2N_BN_SYMBOL(curve25519_x25519base):
 
 // Save regs and make room for temporaries
@@ -850,11 +820,14 @@ scalarloop:
 
 // Extended-projective and precomputed mixed addition.
 // This is effectively the same as calling the standalone
-// function edwards25519_pepadd(acc,acc,tabent)
-
-        double_4(t0,z_1)
-        sub_4(t1,y_1,x_1)
-        add_4(t2,y_1,x_1)
+// function edwards25519_pepadd(acc,acc,tabent), but we
+// only retain slightly weaker normalization < 2 * p_25519
+// throughout the inner loop, so the computation is
+// slightly different, and faster overall.
+
+        double_twice4(t0,z_1)
+        sub_twice4(t1,y_1,x_1)
+        add_twice4(t2,y_1,x_1)
         mul_4(t3,w_1,kxy_2)
         mul_4(t1,t1,ymx_2)
         mul_4(t2,t2,xpy_2)
@@ -862,10 +835,10 @@ scalarloop:
         add_twice4(t0,t0,t3)
         sub_twice4(t5,t2,t1)
         add_twice4(t1,t2,t1)
-        mul_p25519(z_3,t4,t0)
-        mul_p25519(x_3,t5,t4)
-        mul_p25519(y_3,t0,t1)
-        mul_p25519(w_3,t5,t1)
+        mul_4(z_3,t4,t0)
+        mul_4(x_3,t5,t4)
+        mul_4(y_3,t0,t1)
+        mul_4(w_3,t5,t1)
 
 // End of the main loop; move on by 4 bits.
 
@@ -898,10 +871,12 @@ scalarloop:
 //
 // First the addition and subtraction:
 
-        add_4(y_3,x_3,w_3)
-        sub_4(z_3,x_3,w_3)
+        add_twice4(y_3,x_3,w_3)
+        sub_twice4(z_3,x_3,w_3)
 
 // Prepare to call the modular inverse function to get x_3 = 1/z_3
+// Note that this works for the weakly normalized z_3 equally well.
+// The non-coprime case z_3 == 0 (mod p_25519) cannot arise anyway.
 
         mov     x0, 4
         add     x1, x_3
@@ -1245,6 +1220,9 @@ zfliploop:
         b.hi    outerloop
 
 // The final result is (X + T) / (X - T)
+// This is the only operation in the whole computation that
+// fully reduces modulo p_25519 since now we want the canonical
+// answer as output.
 
         mul_p25519(resx,y_3,x_3)
 
diff --git a/arm/curve25519/curve25519_x25519base_alt.S b/arm/curve25519/curve25519_x25519base_alt.S
index 1ab9551f5..0631ac027 100644
--- a/arm/curve25519/curve25519_x25519base_alt.S
+++ b/arm/curve25519/curve25519_x25519base_alt.S
@@ -282,55 +282,6 @@
         stp     x12, x13, [P0];                 \
         stp     x14, x15, [P0+16]
 
-// Plain 4-digit add and doubling without any normalization
-// With inputs < p_25519 (indeed < 2^255) it still gives a 4-digit result,
-// indeed one < 2 * p_25519 for normalized inputs.
-
-#define add_4(P0,P1,P2)                         \
-        ldp     x0, x1, [P1];                   \
-        ldp     x4, x5, [P2];                   \
-        adds    x0, x0, x4;                     \
-        adcs    x1, x1, x5;                     \
-        ldp     x2, x3, [P1+16];                \
-        ldp     x6, x7, [P2+16];                \
-        adcs    x2, x2, x6;                     \
-        adc     x3, x3, x7;                     \
-        stp     x0, x1, [P0];                   \
-        stp     x2, x3, [P0+16]
-
-#define double_4(P0,P1)                         \
-        ldp     x0, x1, [P1];                   \
-        adds    x0, x0, x0;                     \
-        adcs    x1, x1, x1;                     \
-        ldp     x2, x3, [P1+16];                \
-        adcs    x2, x2, x2;                     \
-        adc     x3, x3, x3;                     \
-        stp     x0, x1, [P0];                   \
-        stp     x2, x3, [P0+16]
-
-// Subtraction of a pair of numbers < p_25519 just sufficient
-// to give a 4-digit result. It actually always does (x - z) + (2^255-19)
-// which in turn is done by (x - z) - (2^255+19) discarding the 2^256
-// implicitly
-
-#define sub_4(P0,P1,P2)                         \
-        ldp     x5, x6, [P1];                   \
-        ldp     x4, x3, [P2];                   \
-        subs    x5, x5, x4;                     \
-        sbcs    x6, x6, x3;                     \
-        ldp     x7, x8, [P1+16];                \
-        ldp     x4, x3, [P2+16];                \
-        sbcs    x7, x7, x4;                     \
-        sbcs    x8, x8, x3;                     \
-        mov     x3, #19;                        \
-        subs    x5, x5, x3;                     \
-        sbcs    x6, x6, xzr;                    \
-        sbcs    x7, x7, xzr;                    \
-        mov     x4, #0x8000000000000000;        \
-        sbc     x8, x8, x4;                     \
-        stp     x5, x6, [P0];                   \
-        stp     x7, x8, [P0+16]
-
 // Modular subtraction with double modulus 2 * p_25519 = 2^256 - 38
 
 #define sub_twice4(P0,P1,P2)                    \
@@ -351,8 +302,11 @@
         stp     x5, x6, [P0];                   \
         stp     x7, x8, [P0+16]
 
-// Modular addition with inputs double modulus 2 * p_25519 = 2^256 - 38
-// and in general only guaranteeing a 4-digit result, not even < 2 * p_25519.
+// Modular addition and doubling with double modulus 2 * p_25519 = 2^256 - 38.
+// This only ensures that the result fits in 4 digits, not that it is reduced
+// even w.r.t. double modulus. The result is always correct modulo provided
+// the sum of the inputs is < 2^256 + 2^256 - 38, so in particular provided
+// at least one of them is reduced double modulo.
 
 #define add_twice4(P0,P1,P2)                    \
         ldp     x3, x4, [P1];                   \
@@ -372,6 +326,22 @@
         stp     x3, x4, [P0];                   \
         stp     x5, x6, [P0+16]
 
+#define double_twice4(P0,P1)                    \
+        ldp     x3, x4, [P1];                   \
+        adds    x3, x3, x3;                     \
+        adcs    x4, x4, x4;                     \
+        ldp     x5, x6, [P1+16];                \
+        adcs    x5, x5, x5;                     \
+        adcs    x6, x6, x6;                     \
+        mov     x9, #38;                        \
+        csel    x9, x9, xzr, cs;                \
+        adds    x3, x3, x9;                     \
+        adcs    x4, x4, xzr;                    \
+        adcs    x5, x5, xzr;                    \
+        adc     x6, x6, xzr;                    \
+        stp     x3, x4, [P0];                   \
+        stp     x5, x6, [P0+16]
+
 S2N_BN_SYMBOL(curve25519_x25519base_alt):
 
 // Save regs and make room for temporaries
@@ -732,11 +702,14 @@ scalarloop:
 
 // Extended-projective and precomputed mixed addition.
 // This is effectively the same as calling the standalone
-// function edwards25519_pepadd_alt(acc,acc,tabent)
-
-        double_4(t0,z_1)
-        sub_4(t1,y_1,x_1)
-        add_4(t2,y_1,x_1)
+// function edwards25519_pepadd_alt(acc,acc,tabent), but we
+// only retain slightly weaker normalization < 2 * p_25519
+// throughout the inner loop, so the computation is
+// slightly different, and faster overall.
+
+        double_twice4(t0,z_1)
+        sub_twice4(t1,y_1,x_1)
+        add_twice4(t2,y_1,x_1)
         mul_4(t3,w_1,kxy_2)
         mul_4(t1,t1,ymx_2)
         mul_4(t2,t2,xpy_2)
@@ -744,10 +717,10 @@ scalarloop:
         add_twice4(t0,t0,t3)
         sub_twice4(t5,t2,t1)
         add_twice4(t1,t2,t1)
-        mul_p25519(z_3,t4,t0)
-        mul_p25519(x_3,t5,t4)
-        mul_p25519(y_3,t0,t1)
-        mul_p25519(w_3,t5,t1)
+        mul_4(z_3,t4,t0)
+        mul_4(x_3,t5,t4)
+        mul_4(y_3,t0,t1)
+        mul_4(w_3,t5,t1)
 
 // End of the main loop; move on by 4 bits.
 
@@ -780,10 +753,12 @@ scalarloop:
 //
 // First the addition and subtraction:
 
-        add_4(y_3,x_3,w_3)
-        sub_4(z_3,x_3,w_3)
+        add_twice4(y_3,x_3,w_3)
+        sub_twice4(z_3,x_3,w_3)
 
 // Prepare to call the modular inverse function to get x_3 = 1/z_3
+// Note that this works for the weakly normalized z_3 equally well.
+// The non-coprime case z_3 == 0 (mod p_25519) cannot arise anyway.
 
         mov     x0, 4
         add     x1, x_3
@@ -1127,6 +1102,9 @@ zfliploop:
         b.hi    outerloop
 
 // The final result is (X + T) / (X - T)
+// This is the only operation in the whole computation that
+// fully reduces modulo p_25519 since now we want the canonical
+// answer as output.
 
         mul_p25519(resx,y_3,x_3)
 
diff --git a/x86_att/curve25519/curve25519_x25519base.S b/x86_att/curve25519/curve25519_x25519base.S
index 673287830..1f9ee2377 100644
--- a/x86_att/curve25519/curve25519_x25519base.S
+++ b/x86_att/curve25519/curve25519_x25519base.S
@@ -256,62 +256,6 @@
         movq   %r10, 0x10+P0 ;                  \
         movq   %r11, 0x18+P0
 
-// Plain 4-digit add and doubling without any normalization
-// With inputs < p_25519 (indeed < 2^255) it still gives a 4-digit result,
-// indeed one < 2 * p_25519 for normalized inputs.
-
-#define add_4(P0,P1,P2)                         \
-        movq    P1, %rax ;                      \
-        addq    P2, %rax ;                      \
-        movq    %rax, P0 ;                      \
-        movq    8+P1, %rax ;                    \
-        adcq    8+P2, %rax ;                    \
-        movq    %rax, 8+P0 ;                    \
-        movq    16+P1, %rax ;                   \
-        adcq    16+P2, %rax ;                   \
-        movq    %rax, 16+P0 ;                   \
-        movq    24+P1, %rax ;                   \
-        adcq    24+P2, %rax ;                   \
-        movq    %rax, 24+P0
-
-#define double_4(P0,P1)                         \
-        movq    P1, %rax ;                      \
-        addq    %rax, %rax ;                       \
-        movq    %rax, P0 ;                      \
-        movq    8+P1, %rax ;                    \
-        adcq    %rax, %rax ;                       \
-        movq    %rax, 8+P0 ;                    \
-        movq    16+P1, %rax ;                   \
-        adcq    %rax, %rax ;                       \
-        movq    %rax, 16+P0 ;                   \
-        movq    24+P1, %rax ;                   \
-        adcq    %rax, %rax ;                       \
-        movq    %rax, 24+P0
-
-// Subtraction of a pair of numbers < p_25519 just sufficient
-// to give a 4-digit result. It actually always does (x - z) + (2^255-19)
-// which in turn is done by (x - z) - (2^255+19) discarding the 2^256
-// implicitly
-
-#define sub_4(P0,P1,P2)                         \
-        movq    P1, %r8 ;                       \
-        subq    P2, %r8 ;                       \
-        movq    8+P1, %r9 ;                     \
-        sbbq    8+P2, %r9 ;                     \
-        movq    16+P1, %r10 ;                   \
-        sbbq    16+P2, %r10 ;                   \
-        movq    24+P1, %rax ;                   \
-        sbbq    24+P2, %rax ;                   \
-        subq    $19, %r8 ;                         \
-        movq    %r8, P0 ;                       \
-        sbbq    $0, %r9 ;                          \
-        movq    %r9, 8+P0 ;                     \
-        sbbq    $0, %r10 ;                         \
-        movq    %r10, 16+P0 ;                   \
-        sbbq    $0, %rax ;                         \
-        btc     $63, %rax ;                        \
-        movq    %rax, 24+P0
-
 // Modular subtraction with double modulus 2 * p_25519 = 2^256 - 38
 
 #define sub_twice4(P0,P1,P2)                    \
@@ -335,8 +279,11 @@
         movq    %r10, 16+P0 ;                   \
         movq    %rax, 24+P0
 
-// Modular addition with inputs double modulus 2 * p_25519 = 2^256 - 38
-// and in general only guaranteeing a 4-digit result, not even < 2 * p_25519.
+// Modular addition and doubling with double modulus 2 * p_25519 = 2^256 - 38.
+// This only ensures that the result fits in 4 digits, not that it is reduced
+// even w.r.t. double modulus. The result is always correct modulo provided
+// the sum of the inputs is < 2^256 + 2^256 - 38, so in particular provided
+// at least one of them is reduced double modulo.
 
 #define add_twice4(P0,P1,P2)                    \
         movq    P1, %r8 ;                       \
@@ -359,6 +306,27 @@
         movq    %r10, 0x10+P0 ;                 \
         movq    %r11, 0x18+P0
 
+#define double_twice4(P0,P1)                    \
+        movq    P1, %r8 ;                       \
+        xorl    %ecx, %ecx ;                       \
+        addq    %r8, %r8 ;                         \
+        movq    0x8+P1, %r9 ;                   \
+        adcq    %r9, %r9 ;                         \
+        movq    0x10+P1, %r10 ;                 \
+        adcq    %r10, %r10 ;                       \
+        movq    0x18+P1, %r11 ;                 \
+        adcq    %r11, %r11 ;                       \
+        movl    $38, %eax ;                        \
+        cmovncq %rcx, %rax ;                       \
+        addq    %rax, %r8 ;                        \
+        adcq    %rcx, %r9 ;                        \
+        adcq    %rcx, %r10 ;                       \
+        adcq    %rcx, %r11 ;                       \
+        movq    %r8, P0 ;                       \
+        movq    %r9, 0x8+P0 ;                   \
+        movq    %r10, 0x10+P0 ;                 \
+        movq    %r11, 0x18+P0
+
 S2N_BN_SYMBOL(curve25519_x25519base):
 
 // In this case the Windows form literally makes a subroutine call.
@@ -845,11 +813,14 @@ scalarloop:
 
 // Extended-projective and precomputed mixed addition.
 // This is effectively the same as calling the standalone
-// function edwards25519_pepadd(acc,acc,tabent)
-
-        double_4(t0,z_1)
-        sub_4(t1,y_1,x_1)
-        add_4(t2,y_1,x_1)
+// function edwards25519_pepadd(acc,acc,tabent), but we
+// only retain slightly weaker normalization < 2 * p_25519
+// throughout the inner loop, so the computation is
+// slightly different, and faster overall.
+
+        double_twice4(t0,z_1)
+        sub_twice4(t1,y_1,x_1)
+        add_twice4(t2,y_1,x_1)
         mul_4(t3,w_1,kxy_2)
         mul_4(t1,t1,ymx_2)
         mul_4(t2,t2,xpy_2)
@@ -857,10 +828,10 @@ scalarloop:
         add_twice4(t0,t0,t3)
         sub_twice4(t5,t2,t1)
         add_twice4(t1,t2,t1)
-        mul_p25519(z_3,t4,t0)
-        mul_p25519(x_3,t5,t4)
-        mul_p25519(y_3,t0,t1)
-        mul_p25519(w_3,t5,t1)
+        mul_4(z_3,t4,t0)
+        mul_4(x_3,t5,t4)
+        mul_4(y_3,t0,t1)
+        mul_4(w_3,t5,t1)
 
 // End of the main loop; move on by 4 bits.
 
@@ -893,10 +864,12 @@ scalarloop:
 //
 // First the addition and subtraction:
 
-        add_4(y_3,x_3,w_3)
-        sub_4(z_3,x_3,w_3)
+        add_twice4(y_3,x_3,w_3)
+        sub_twice4(z_3,x_3,w_3)
 
 // Prepare to call the modular inverse function to get x_3 = 1/z_3
+// Note that this works for the weakly normalized z_3 equally well.
+// The non-coprime case z_3 == 0 (mod p_25519) cannot arise anyway.
 
         movq    $4, %rdi
         leaq    128(%rsp), %rsi
@@ -1303,6 +1276,9 @@ fliploop:
         ja      outerloop
 
 // The final result is (X + T) / (X - T)
+// This is the only operation in the whole computation that
+// fully reduces modulo p_25519 since now we want the canonical
+// answer as output.
 
         movq    res, %rbp
         mul_p25519(resx,y_3,x_3)
diff --git a/x86_att/curve25519/curve25519_x25519base_alt.S b/x86_att/curve25519/curve25519_x25519base_alt.S
index 4e0285088..0027f47f9 100644
--- a/x86_att/curve25519/curve25519_x25519base_alt.S
+++ b/x86_att/curve25519/curve25519_x25519base_alt.S
@@ -332,62 +332,6 @@
         movq    %r10, 0x10+P0 ;                 \
         movq    %r11, 0x18+P0
 
-// Plain 4-digit add and doubling without any normalization
-// With inputs < p_25519 (indeed < 2^255) it still gives a 4-digit result,
-// indeed one < 2 * p_25519 for normalized inputs.
-
-#define add_4(P0,P1,P2)                         \
-        movq    P1, %rax ;                      \
-        addq    P2, %rax ;                      \
-        movq    %rax, P0 ;                      \
-        movq    8+P1, %rax ;                    \
-        adcq    8+P2, %rax ;                    \
-        movq    %rax, 8+P0 ;                    \
-        movq    16+P1, %rax ;                   \
-        adcq    16+P2, %rax ;                   \
-        movq    %rax, 16+P0 ;                   \
-        movq    24+P1, %rax ;                   \
-        adcq    24+P2, %rax ;                   \
-        movq    %rax, 24+P0
-
-#define double_4(P0,P1)                         \
-        movq    P1, %rax ;                      \
-        addq    %rax, %rax ;                       \
-        movq    %rax, P0 ;                      \
-        movq    8+P1, %rax ;                    \
-        adcq    %rax, %rax ;                       \
-        movq    %rax, 8+P0 ;                    \
-        movq    16+P1, %rax ;                   \
-        adcq    %rax, %rax ;                       \
-        movq    %rax, 16+P0 ;                   \
-        movq    24+P1, %rax ;                   \
-        adcq    %rax, %rax ;                       \
-        movq    %rax, 24+P0
-
-// Subtraction of a pair of numbers < p_25519 just sufficient
-// to give a 4-digit result. It actually always does (x - z) + (2^255-19)
-// which in turn is done by (x - z) - (2^255+19) discarding the 2^256
-// implicitly
-
-#define sub_4(P0,P1,P2)                         \
-        movq    P1, %r8 ;                       \
-        subq    P2, %r8 ;                       \
-        movq    8+P1, %r9 ;                     \
-        sbbq    8+P2, %r9 ;                     \
-        movq    16+P1, %r10 ;                   \
-        sbbq    16+P2, %r10 ;                   \
-        movq    24+P1, %rax ;                   \
-        sbbq    24+P2, %rax ;                   \
-        subq    $19, %r8 ;                         \
-        movq    %r8, P0 ;                       \
-        sbbq    $0, %r9 ;                          \
-        movq    %r9, 8+P0 ;                     \
-        sbbq    $0, %r10 ;                         \
-        movq    %r10, 16+P0 ;                   \
-        sbbq    $0, %rax ;                         \
-        btc     $63, %rax ;                        \
-        movq    %rax, 24+P0
-
 // Modular subtraction with double modulus 2 * p_25519 = 2^256 - 38
 
 #define sub_twice4(P0,P1,P2)                    \
@@ -411,8 +355,11 @@
         movq    %r10, 16+P0 ;                   \
         movq    %rax, 24+P0
 
-// Modular addition with inputs double modulus 2 * p_25519 = 2^256 - 38
-// and in general only guaranteeing a 4-digit result, not even < 2 * p_25519.
+// Modular addition and doubling with double modulus 2 * p_25519 = 2^256 - 38.
+// This only ensures that the result fits in 4 digits, not that it is reduced
+// even w.r.t. double modulus. The result is always correct modulo provided
+// the sum of the inputs is < 2^256 + 2^256 - 38, so in particular provided
+// at least one of them is reduced double modulo.
 
 #define add_twice4(P0,P1,P2)                    \
         movq    P1, %r8 ;                       \
@@ -435,6 +382,27 @@
         movq    %r10, 0x10+P0 ;                 \
         movq    %r11, 0x18+P0
 
+#define double_twice4(P0,P1)                    \
+        movq    P1, %r8 ;                       \
+        xorl    %ecx, %ecx ;                       \
+        addq    %r8, %r8 ;                         \
+        movq    0x8+P1, %r9 ;                   \
+        adcq    %r9, %r9 ;                         \
+        movq    0x10+P1, %r10 ;                 \
+        adcq    %r10, %r10 ;                       \
+        movq    0x18+P1, %r11 ;                 \
+        adcq    %r11, %r11 ;                       \
+        movl    $38, %eax ;                        \
+        cmovncq %rcx, %rax ;                       \
+        addq    %rax, %r8 ;                        \
+        adcq    %rcx, %r9 ;                        \
+        adcq    %rcx, %r10 ;                       \
+        adcq    %rcx, %r11 ;                       \
+        movq    %r8, P0 ;                       \
+        movq    %r9, 0x8+P0 ;                   \
+        movq    %r10, 0x10+P0 ;                 \
+        movq    %r11, 0x18+P0
+
 S2N_BN_SYMBOL(curve25519_x25519base_alt):
 
 // In this case the Windows form literally makes a subroutine call.
@@ -921,11 +889,14 @@ scalarloop:
 
 // Extended-projective and precomputed mixed addition.
 // This is effectively the same as calling the standalone
-// function edwards25519_pepadd_alt(acc,acc,tabent)
-
-        double_4(t0,z_1)
-        sub_4(t1,y_1,x_1)
-        add_4(t2,y_1,x_1)
+// function edwards25519_pepadd_alt(acc,acc,tabent), but we
+// only retain slightly weaker normalization < 2 * p_25519
+// throughout the inner loop, so the computation is
+// slightly different, and faster overall.
+
+        double_twice4(t0,z_1)
+        sub_twice4(t1,y_1,x_1)
+        add_twice4(t2,y_1,x_1)
         mul_4(t3,w_1,kxy_2)
         mul_4(t1,t1,ymx_2)
         mul_4(t2,t2,xpy_2)
@@ -933,10 +904,10 @@ scalarloop:
         add_twice4(t0,t0,t3)
         sub_twice4(t5,t2,t1)
         add_twice4(t1,t2,t1)
-        mul_p25519(z_3,t4,t0)
-        mul_p25519(x_3,t5,t4)
-        mul_p25519(y_3,t0,t1)
-        mul_p25519(w_3,t5,t1)
+        mul_4(z_3,t4,t0)
+        mul_4(x_3,t5,t4)
+        mul_4(y_3,t0,t1)
+        mul_4(w_3,t5,t1)
 
 // End of the main loop; move on by 4 bits.
 
@@ -969,8 +940,8 @@ scalarloop:
 //
 // First the addition and subtraction:
 
-        add_4(y_3,x_3,w_3)
-        sub_4(z_3,x_3,w_3)
+        add_twice4(y_3,x_3,w_3)
+        sub_twice4(z_3,x_3,w_3)
 
 // Prepare to call the modular inverse function to get x_3 = 1/z_3
 
@@ -1379,6 +1350,9 @@ fliploop:
         ja      outerloop
 
 // The final result is (X + T) / (X - T)
+// This is the only operation in the whole computation that
+// fully reduces modulo p_25519 since now we want the canonical
+// answer as output.
 
         movq    res, %rbp
         mul_p25519(resx,y_3,x_3)
