From 8a059b7e6a6085f154fd0e4a9706c5f8626cd03c Mon Sep 17 00:00:00 2001
From: John Harrison <jargh@amazon.com>
Date: Thu, 19 Aug 2021 13:39:50 -0700
Subject: [PATCH] Consistently use upper case for constants

Numeric constants from "#define" and assembler-level values
from ".set" are now always uppercase. This makes it easier to parse
the assembler files in a context-free way for scripting purposes.
This does not change the text section of any object file and hence
does not require proof changes. However the .set directives do
add a symbol to the symbol table, and those have changed in the
following from "i" to "I":

        arm/fastmul/bignum_kmul_16_32.o
        arm/fastmul/bignum_kmul_32_64.o
        arm/fastmul/bignum_ksqr_16_32.o
        arm/fastmul/bignum_ksqr_32_64.o
        arm/p256/bignum_mux_4.o
        arm/p384/bignum_mux_6.o
        arm/p521/bignum_double_p521.o
        x86/fastmul/bignum_kmul_32_64.o
        x86/fastmul/bignum_ksqr_16_32.o
        x86/fastmul/bignum_ksqr_32_64.o
        x86/p256/bignum_mux_4.o
        x86/p384/bignum_mux_6.o
        x86/p521/bignum_double_p521.o

s2n-bignum original commit: https://github.com/awslabs/s2n-bignum/commit/6a61485209419b2ee05e7065e8619fb77de9118f
---
 arm/fastmul/bignum_kmul_16_32.S |  24 +++----
 arm/fastmul/bignum_kmul_32_64.S | 122 ++++++++++++++++----------------
 arm/fastmul/bignum_ksqr_16_32.S |  24 +++----
 arm/fastmul/bignum_ksqr_32_64.S | 106 +++++++++++++--------------
 arm/p384/bignum_mux_6.S         |  10 +--
 arm/p521/bignum_double_p521.S   |   8 +--
 6 files changed, 147 insertions(+), 147 deletions(-)

diff --git a/arm/fastmul/bignum_kmul_16_32.S b/arm/fastmul/bignum_kmul_16_32.S
index e1acfc8ba..4f527800a 100644
--- a/arm/fastmul/bignum_kmul_16_32.S
+++ b/arm/fastmul/bignum_kmul_16_32.S
@@ -159,30 +159,30 @@ bignum_kmul_16_32:
 // Compute H' = H + L_top in place of H (it cannot overflow)
 // First add 8-sized block then propagate carry through next 8
 
-        .set    i, 0
+        .set    I, 0
 
-        ldp     x10, x11, [z, #128+8*i]
-        ldp     x12, x13, [z, #64+8*i]
+        ldp     x10, x11, [z, #128+8*I]
+        ldp     x12, x13, [z, #64+8*I]
         adds    x10, x10, x12
         adcs    x11, x11, x13
-        stp     x10, x11, [z, #128+8*i]
-        .set    i, (i+2)
+        stp     x10, x11, [z, #128+8*I]
+        .set    I, (I+2)
 
 .rep 3
-        ldp     x10, x11, [z, #128+8*i]
-        ldp     x12, x13, [z, #64+8*i]
+        ldp     x10, x11, [z, #128+8*I]
+        ldp     x12, x13, [z, #64+8*I]
         adcs    x10, x10, x12
         adcs    x11, x11, x13
-        stp     x10, x11, [z, #128+8*i]
-        .set    i, (i+2)
+        stp     x10, x11, [z, #128+8*I]
+        .set    I, (I+2)
 .endr
 
 .rep 4
-        ldp     x10, x11, [z, #128+8*i]
+        ldp     x10, x11, [z, #128+8*I]
         adcs    x10, x10, xzr
         adcs    x11, x11, xzr
-        stp     x10, x11, [z, #128+8*i]
-        .set    i, (i+2)
+        stp     x10, x11, [z, #128+8*I]
+        .set    I, (I+2)
 .endr
 
 // Compute M = |x_lo - x_hi| * |y_hi - y_lo| in [t+16...], size 16
diff --git a/arm/fastmul/bignum_kmul_32_64.S b/arm/fastmul/bignum_kmul_32_64.S
index 7ba4d8f87..dd6b86b20 100644
--- a/arm/fastmul/bignum_kmul_32_64.S
+++ b/arm/fastmul/bignum_kmul_32_64.S
@@ -30,8 +30,8 @@
         .globl  bignum_kmul_32_64
         .text
 
-#define k 16
-#define l (k/2)
+#define K 16
+#define L (K/2)
 
 #define z x19
 #define x x20
@@ -62,9 +62,9 @@ bignum_kmul_32_64:
 
 // Compute H = x_hi * y_hi in top half of buffer (size 16 x 16 -> 32)
 
-        add     x0, z, 8*2*k
-        add     x1, x, 8*k
-        add     x2, y, 8*k
+        add     x0, z, 8*2*K
+        add     x1, x, 8*K
+        add     x2, y, 8*K
         mov     x3, t
         bl      local_kmul_16_32
 
@@ -165,7 +165,7 @@ bignum_kmul_32_64:
         adc     x15, x15, xzr
         stp     x14, x15, [t, 112]
 
-// Compute the other absolute difference [t+8*k..] = |y_hi - y_lo|
+// Compute the other absolute difference [t+8*K..] = |y_hi - y_lo|
 // Collect the combined product sign bitmask (all 1s for negative) as
 // y = sgn((x_lo - x_hi) * (y_hi - y_lo)), overwriting the y pointer.
 
@@ -217,119 +217,119 @@ bignum_kmul_32_64:
         adcs    x0, x0, xzr
         eor     x1, x1, y
         adcs    x1, x1, xzr
-        stp     x0, x1, [t, 8*k]
+        stp     x0, x1, [t, 8*K]
 
         eor     x2, x2, y
         adcs    x2, x2, xzr
         eor     x3, x3, y
         adcs    x3, x3, xzr
-        stp     x2, x3, [t, 8*k+16]
+        stp     x2, x3, [t, 8*K+16]
 
         eor     x4, x4, y
         adcs    x4, x4, xzr
         eor     x5, x5, y
         adcs    x5, x5, xzr
-        stp     x4, x5, [t, 8*k+32]
+        stp     x4, x5, [t, 8*K+32]
 
         eor     x6, x6, y
         adcs    x6, x6, xzr
         eor     x7, x7, y
         adcs    x7, x7, xzr
-        stp     x6, x7, [t, 8*k+48]
+        stp     x6, x7, [t, 8*K+48]
 
         eor     x8, x8, y
         adcs    x8, x8, xzr
         eor     x9, x9, y
         adcs    x9, x9, xzr
-        stp     x8, x9, [t, 8*k+64]
+        stp     x8, x9, [t, 8*K+64]
 
         eor     x10, x10, y
         adcs    x10, x10, xzr
         eor     x11, x11, y
         adcs    x11, x11, xzr
-        stp     x10, x11, [t, 8*k+80]
+        stp     x10, x11, [t, 8*K+80]
 
         eor     x12, x12, y
         adcs    x12, x12, xzr
         eor     x13, x13, y
         adcs    x13, x13, xzr
-        stp     x12, x13, [t, 8*k+96]
+        stp     x12, x13, [t, 8*K+96]
 
         eor     x14, x14, y
         adcs    x14, x14, xzr
         eor     x15, x15, y
         adc     x15, x15, xzr
-        stp     x14, x15, [t, 8*k+112]
+        stp     x14, x15, [t, 8*K+112]
 
         eor     y, y, x
 
 // Compute H' = H + L_top in place of H (it cannot overflow)
 
-        ldp     x0, x1, [z, 16*k]
-        ldp     x2, x3, [z, 16*l]
+        ldp     x0, x1, [z, 16*K]
+        ldp     x2, x3, [z, 16*L]
         adds    x0, x0, x2
         adcs    x1, x1, x3
-        stp     x0, x1, [z, 16*k]
+        stp     x0, x1, [z, 16*K]
 
-        .set    i, 1
-        .rep (l-1)
-        ldp     x0, x1, [z, 16*(k+i)]
-        ldp     x2, x3, [z, 16*(l+i)]
+        .set    I, 1
+        .rep (L-1)
+        ldp     x0, x1, [z, 16*(K+I)]
+        ldp     x2, x3, [z, 16*(L+I)]
         adcs    x0, x0, x2
         adcs    x1, x1, x3
-        stp     x0, x1, [z, 16*(k+i)]
-        .set    i, (i+1)
+        stp     x0, x1, [z, 16*(K+I)]
+        .set    I, (I+1)
         .endr
 
-        .rep    (l-1)
-        ldp     x0, x1, [z, 16*(k+i)]
+        .rep    (L-1)
+        ldp     x0, x1, [z, 16*(K+I)]
         adcs    x0, x0, xzr
         adcs    x1, x1, xzr
-        stp     x0, x1, [z, 16*(k+i)]
-        .set    i, (i+1)
+        stp     x0, x1, [z, 16*(K+I)]
+        .set    I, (I+1)
         .endr
 
-        ldp     x0, x1, [z, 16*(k+i)]
+        ldp     x0, x1, [z, 16*(K+I)]
         adcs    x0, x0, xzr
         adc     x1, x1, xzr
-        stp     x0, x1, [z, 16*(k+i)]
+        stp     x0, x1, [z, 16*(K+I)]
 
 // Compute M = |x_lo - x_hi| * |y_hi - y_lo|, size 32
 
-        add     x0, t, 16*k
+        add     x0, t, 16*K
         mov     x1, t
-        add     x2, t, 8*k
-        add     x3, t, 8*4*k
+        add     x2, t, 8*K
+        add     x3, t, 8*4*K
         bl      local_kmul_16_32
 
 // Add the interlocking H' and L_bot terms
 // Intercept the carry at the 3k position and store it in x.
 // Again, we no longer need the input x was pointing at.
 
-        ldp     x0, x1, [z, 16*k]
+        ldp     x0, x1, [z, 16*K]
         ldp     x2, x3, [z]
         adds    x0, x0, x2
         adcs    x1, x1, x3
-        stp     x0, x1, [z, 16*l]
+        stp     x0, x1, [z, 16*L]
 
-        .set    i, 1
-        .rep (l-1)
-        ldp     x0, x1, [z, 16*(k+i)]
-        ldp     x2, x3, [z, 16*i]
+        .set    I, 1
+        .rep (L-1)
+        ldp     x0, x1, [z, 16*(K+I)]
+        ldp     x2, x3, [z, 16*I]
         adcs    x0, x0, x2
         adcs    x1, x1, x3
-        stp     x0, x1, [z, 16*(l+i)]
-        .set    i, (i+1)
+        stp     x0, x1, [z, 16*(L+I)]
+        .set    I, (I+1)
         .endr
 
-        .set    i, 0
-        .rep    l
-        ldp     x0, x1, [z, 16*(k+i)]
-        ldp     x2, x3, [z, 16*(3*l+i)]
+        .set    I, 0
+        .rep    L
+        ldp     x0, x1, [z, 16*(K+I)]
+        ldp     x2, x3, [z, 16*(3*L+I)]
         adcs    x0, x0, x2
         adcs    x1, x1, x3
-        stp     x0, x1, [z, 16*(k+i)]
-        .set    i, (i+1)
+        stp     x0, x1, [z, 16*(K+I)]
+        .set    I, (I+1)
         .endr
 
         cset      x, cs
@@ -338,16 +338,16 @@ bignum_kmul_32_64:
 
         cmn     y, y
 
-        .set    i, l
-        .rep k
-        ldp     x0, x1, [z, 16*i]
-        ldp     x2, x3, [t, 8*k+16*i]
+        .set    I, L
+        .rep K
+        ldp     x0, x1, [z, 16*I]
+        ldp     x2, x3, [t, 8*K+16*I]
         eor     x2, x2, y
         adcs    x0, x0, x2
         eor     x3, x3, y
         adcs    x1, x1, x3
-        stp     x0, x1, [z, 16*i]
-        .set    i, (i+1)
+        stp     x0, x1, [z, 16*I]
+        .set    I, (I+1)
         .endr
 
 // Get the next digits effectively resulting so far starting at 3k
@@ -358,24 +358,24 @@ bignum_kmul_32_64:
 
 // Now propagate through the top quarter of the result
 
-        ldp     x0, x1, [z, 16*3*l]
+        ldp     x0, x1, [z, 16*3*L]
         adds    x0, x0, x
         adcs    x1, x1, c
-        stp     x0, x1, [z, 16*3*l]
+        stp     x0, x1, [z, 16*3*L]
 
-        .set    i, 3*l+1
-        .rep    (l-2)
-        ldp     x0, x1, [z, 16*i]
+        .set    I, 3*L+1
+        .rep    (L-2)
+        ldp     x0, x1, [z, 16*I]
         adcs    x0, x0, c
         adcs    x1, x1, c
-        stp     x0, x1, [z, 16*i]
-        .set    i, (i+1)
+        stp     x0, x1, [z, 16*I]
+        .set    I, (I+1)
         .endr
 
-        ldp     x0, x1, [z, 16*i]
+        ldp     x0, x1, [z, 16*I]
         adcs    x0, x0, c
         adc     x1, x1, c
-        stp     x0, x1, [z, 16*i]
+        stp     x0, x1, [z, 16*I]
 
 // Restore and return
 
diff --git a/arm/fastmul/bignum_ksqr_16_32.S b/arm/fastmul/bignum_ksqr_16_32.S
index ad1a9dcef..ede9559f6 100644
--- a/arm/fastmul/bignum_ksqr_16_32.S
+++ b/arm/fastmul/bignum_ksqr_16_32.S
@@ -109,30 +109,30 @@ bignum_ksqr_16_32:
 // Compute H' = H + L_top in place of H (it cannot overflow)
 // First add 8-sized block then propagate carry through next 8
 
-        .set    i, 0
+        .set    I, 0
 
-        ldp     x10, x11, [z, #128+8*i]
-        ldp     x12, x13, [z, #64+8*i]
+        ldp     x10, x11, [z, #128+8*I]
+        ldp     x12, x13, [z, #64+8*I]
         adds    x10, x10, x12
         adcs    x11, x11, x13
-        stp     x10, x11, [z, #128+8*i]
-        .set    i, (i+2)
+        stp     x10, x11, [z, #128+8*I]
+        .set    I, (I+2)
 
 .rep 3
-        ldp     x10, x11, [z, #128+8*i]
-        ldp     x12, x13, [z, #64+8*i]
+        ldp     x10, x11, [z, #128+8*I]
+        ldp     x12, x13, [z, #64+8*I]
         adcs    x10, x10, x12
         adcs    x11, x11, x13
-        stp     x10, x11, [z, #128+8*i]
-        .set    i, (i+2)
+        stp     x10, x11, [z, #128+8*I]
+        .set    I, (I+2)
 .endr
 
 .rep 4
-        ldp     x10, x11, [z, #128+8*i]
+        ldp     x10, x11, [z, #128+8*I]
         adcs    x10, x10, xzr
         adcs    x11, x11, xzr
-        stp     x10, x11, [z, #128+8*i]
-        .set    i, (i+2)
+        stp     x10, x11, [z, #128+8*I]
+        .set    I, (I+2)
 .endr
 
 // Compute M = |x_lo - x_hi| * |y_hi - y_lo| in [t+8...], size 16
diff --git a/arm/fastmul/bignum_ksqr_32_64.S b/arm/fastmul/bignum_ksqr_32_64.S
index 2a20b8766..3a9d5895f 100644
--- a/arm/fastmul/bignum_ksqr_32_64.S
+++ b/arm/fastmul/bignum_ksqr_32_64.S
@@ -29,8 +29,8 @@
         .globl  bignum_ksqr_32_64
         .text
 
-#define k 16
-#define l (k/2)
+#define K 16
+#define L (K/2)
 
 #define z x19
 #define x x20
@@ -56,41 +56,41 @@ bignum_ksqr_32_64:
 
 // Compute H = x_hi * y_hi in top half of buffer (size 16 x 16 -> 32)
 
-        add     x0, z, #8*2*k
-        add     x1, x, #8*k
+        add     x0, z, #8*2*K
+        add     x1, x, #8*K
         mov     x2, t
         bl      local_ksqr_16_32
 
 // Compute H' = H + L_top in place of H (it cannot overflow)
 
-        ldp     x0, x1, [z, #16*k]
-        ldp     x2, x3, [z, #16*l]
+        ldp     x0, x1, [z, #16*K]
+        ldp     x2, x3, [z, #16*L]
         adds    x0, x0, x2
         adcs    x1, x1, x3
-        stp     x0, x1, [z, #16*k]
+        stp     x0, x1, [z, #16*K]
 
-        .set    i, 1
-        .rep (l-1)
-        ldp     x0, x1, [z, #16*(k+i)]
-        ldp     x2, x3, [z, #16*(l+i)]
+        .set    I, 1
+        .rep (L-1)
+        ldp     x0, x1, [z, #16*(K+I)]
+        ldp     x2, x3, [z, #16*(L+I)]
         adcs    x0, x0, x2
         adcs    x1, x1, x3
-        stp     x0, x1, [z, #16*(k+i)]
-        .set    i, (i+1)
+        stp     x0, x1, [z, #16*(K+I)]
+        .set    I, (I+1)
         .endr
 
-        .rep    (l-1)
-        ldp     x0, x1, [z, #16*(k+i)]
+        .rep    (L-1)
+        ldp     x0, x1, [z, #16*(K+I)]
         adcs    x0, x0, xzr
         adcs    x1, x1, xzr
-        stp     x0, x1, [z, #16*(k+i)]
-        .set    i, (i+1)
+        stp     x0, x1, [z, #16*(K+I)]
+        .set    I, (I+1)
         .endr
 
-        ldp     x0, x1, [z, #16*(k+i)]
+        ldp     x0, x1, [z, #16*(K+I)]
         adcs    x0, x0, xzr
         adc     x1, x1, xzr
-        stp     x0, x1, [z, #16*(k+i)]
+        stp     x0, x1, [z, #16*(K+I)]
 
 // Compute absolute difference [t..] = |x_lo - x_hi|
 
@@ -188,59 +188,59 @@ bignum_ksqr_32_64:
 
 // Compute M = |x_lo - x_hi|^2, size 32
 
-        add     x0, t, #8*k
+        add     x0, t, #8*K
         mov     x1, t
-        add     x2, t, #8*3*k
+        add     x2, t, #8*3*K
         bl      local_ksqr_16_32
 
 // Add the interlocking H' and L_bot terms
 // Intercept the carry at the 3k position and store it in x.
 // (Note that we no longer need the input x was pointing at.)
 
-        ldp     x0, x1, [z, #16*k]
+        ldp     x0, x1, [z, #16*K]
         ldp     x2, x3, [z]
         adds    x0, x0, x2
         adcs    x1, x1, x3
-        stp     x0, x1, [z, #16*l]
+        stp     x0, x1, [z, #16*L]
 
-        .set    i, 1
-        .rep (l-1)
-        ldp     x0, x1, [z, #16*(k+i)]
-        ldp     x2, x3, [z, #16*i]
+        .set    I, 1
+        .rep (L-1)
+        ldp     x0, x1, [z, #16*(K+I)]
+        ldp     x2, x3, [z, #16*I]
         adcs    x0, x0, x2
         adcs    x1, x1, x3
-        stp     x0, x1, [z, #16*(l+i)]
-        .set    i, (i+1)
+        stp     x0, x1, [z, #16*(L+I)]
+        .set    I, (I+1)
         .endr
 
-        .set    i, 0
-        .rep    l
-        ldp     x0, x1, [z, #16*(k+i)]
-        ldp     x2, x3, [z, #16*(3*l+i)]
+        .set    I, 0
+        .rep    L
+        ldp     x0, x1, [z, #16*(K+I)]
+        ldp     x2, x3, [z, #16*(3*L+I)]
         adcs    x0, x0, x2
         adcs    x1, x1, x3
-        stp     x0, x1, [z, #16*(k+i)]
-        .set    i, (i+1)
+        stp     x0, x1, [z, #16*(K+I)]
+        .set    I, (I+1)
         .endr
 
         cset      x, cs
 
 // Subtract the mid-term cross product M
 
-        ldp     x0, x1, [z, #16*l]
-        ldp     x2, x3, [t, #16*l]
+        ldp     x0, x1, [z, #16*L]
+        ldp     x2, x3, [t, #16*L]
         subs    x0, x0, x2
         sbcs    x1, x1, x3
-        stp     x0, x1, [z, #16*l]
+        stp     x0, x1, [z, #16*L]
 
-        .set    i, l+1
-        .rep (k-1)
-        ldp     x0, x1, [z, #16*i]
-        ldp     x2, x3, [t, #16*i]
+        .set    I, L+1
+        .rep (K-1)
+        ldp     x0, x1, [z, #16*I]
+        ldp     x2, x3, [t, #16*I]
         sbcs    x0, x0, x2
         sbcs    x1, x1, x3
-        stp     x0, x1, [z, #16*i]
-        .set    i, (i+1)
+        stp     x0, x1, [z, #16*I]
+        .set    I, (I+1)
         .endr
 
 // Get the next digits effectively resulting so far starting at 3k
@@ -251,24 +251,24 @@ bignum_ksqr_32_64:
 
 // Now propagate through the top quarter of the result
 
-        ldp     x0, x1, [z, #16*3*l]
+        ldp     x0, x1, [z, #16*3*L]
         adds    x0, x0, x
         adcs    x1, x1, c
-        stp     x0, x1, [z, #16*3*l]
+        stp     x0, x1, [z, #16*3*L]
 
-        .set    i, 3*l+1
-        .rep    (l-2)
-        ldp     x0, x1, [z, #16*i]
+        .set    I, 3*L+1
+        .rep    (L-2)
+        ldp     x0, x1, [z, #16*I]
         adcs    x0, x0, c
         adcs    x1, x1, c
-        stp     x0, x1, [z, #16*i]
-        .set    i, (i+1)
+        stp     x0, x1, [z, #16*I]
+        .set    I, (I+1)
         .endr
 
-        ldp     x0, x1, [z, #16*i]
+        ldp     x0, x1, [z, #16*I]
         adcs    x0, x0, c
         adc     x1, x1, c
-        stp     x0, x1, [z, #16*i]
+        stp     x0, x1, [z, #16*I]
 
 // Restore
 
diff --git a/arm/p384/bignum_mux_6.S b/arm/p384/bignum_mux_6.S
index 78b68ee86..6acca5152 100644
--- a/arm/p384/bignum_mux_6.S
+++ b/arm/p384/bignum_mux_6.S
@@ -40,13 +40,13 @@ bignum_mux_6:
 
                 cmp     p, #0                    // Set condition codes p = 0
 
-                .set    i, 0
+                .set    I, 0
                 .rep    6
-                ldr     a, [x, #8*i]
-                ldr     p, [y, #8*i]
+                ldr     a, [x, #8*I]
+                ldr     p, [y, #8*I]
                 csel    a, a, p, ne
-                str     a, [z, #8*i]
-                .set    i, (i+1)
+                str     a, [z, #8*I]
+                .set    I, (I+1)
                 .endr
 
                 ret
diff --git a/arm/p521/bignum_double_p521.S b/arm/p521/bignum_double_p521.S
index 5ed66cc4c..7def09818 100644
--- a/arm/p521/bignum_double_p521.S
+++ b/arm/p521/bignum_double_p521.S
@@ -45,13 +45,13 @@ bignum_double_p521:
 // and otherwise just 2 * x. Feed in the condition as the carry bit
 // to get 2 * x + [2 * x >= p_521] then just mask it off to 521 bits.
 
-                .set    i, 0
+                .set    I, 0
                 .rep 4
-                ldp     l, h, [x, #8*i]
+                ldp     l, h, [x, #8*I]
                 adcs    l, l, l
                 adcs    h, h, h
-                stp     l, h, [z, #8*i]
-                .set    i, (i+2)
+                stp     l, h, [z, #8*I]
+                .set    I, (I+2)
                 .endr
 
                 adc     c, c, c
