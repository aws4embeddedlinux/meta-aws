From f13af32217e9651ef54f7aad5237f653d057793e Mon Sep 17 00:00:00 2001
From: John Harrison <jargh@amazon.com>
Date: Mon, 13 Sep 2021 14:13:42 -0700
Subject: [PATCH] Add AT&T syntax versions of x86 P-521 functions

Generated by the same sed script as the P-256 and P-384 ones, again
with sanity check.

s2n-bignum original commit: https://github.com/awslabs/s2n-bignum/commit/72eb1655869655e26c7a8ae6f1a4d7f24591ee41
---
 x86_att/p521/bignum_add_p521.S     | 121 +++++++++++
 x86_att/p521/bignum_cmul_p521.S    | 167 +++++++++++++++
 x86_att/p521/bignum_deamont_p521.S | 139 +++++++++++++
 x86_att/p521/bignum_demont_p521.S  |  88 ++++++++
 x86_att/p521/bignum_double_p521.S  |  90 ++++++++
 x86_att/p521/bignum_half_p521.S    |  99 +++++++++
 x86_att/p521/bignum_mod_p521_9.S   | 116 +++++++++++
 x86_att/p521/bignum_montsqr_p521.S | 316 +++++++++++++++++++++++++++++
 x86_att/p521/bignum_neg_p521.S     |  98 +++++++++
 x86_att/p521/bignum_optneg_p521.S  | 102 ++++++++++
 x86_att/p521/bignum_sqr_p521.S     | 292 ++++++++++++++++++++++++++
 x86_att/p521/bignum_sub_p521.S     | 111 ++++++++++
 x86_att/p521/bignum_triple_p521.S  | 154 ++++++++++++++
 13 files changed, 1893 insertions(+)
 create mode 100644 x86_att/p521/bignum_add_p521.S
 create mode 100644 x86_att/p521/bignum_cmul_p521.S
 create mode 100644 x86_att/p521/bignum_deamont_p521.S
 create mode 100644 x86_att/p521/bignum_demont_p521.S
 create mode 100644 x86_att/p521/bignum_double_p521.S
 create mode 100644 x86_att/p521/bignum_half_p521.S
 create mode 100644 x86_att/p521/bignum_mod_p521_9.S
 create mode 100644 x86_att/p521/bignum_montsqr_p521.S
 create mode 100644 x86_att/p521/bignum_neg_p521.S
 create mode 100644 x86_att/p521/bignum_optneg_p521.S
 create mode 100644 x86_att/p521/bignum_sqr_p521.S
 create mode 100644 x86_att/p521/bignum_sub_p521.S
 create mode 100644 x86_att/p521/bignum_triple_p521.S

diff --git a/x86_att/p521/bignum_add_p521.S b/x86_att/p521/bignum_add_p521.S
new file mode 100644
index 000000000..6a1175957
--- /dev/null
+++ b/x86_att/p521/bignum_add_p521.S
@@ -0,0 +1,121 @@
+/*
+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License").
+ * You may not use this file except in compliance with the License.
+ * A copy of the License is located at
+ *
+ *  http://aws.amazon.com/apache2.0
+ *
+ * or in the "LICENSE" file accompanying this file. This file is distributed
+ * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
+ * express or implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ */
+
+// ----------------------------------------------------------------------------
+// Add modulo p_521, z := (x + y) mod p_521, assuming x and y reduced
+// Inputs x[9], y[9]; output z[9]
+//
+//    extern void bignum_add_p521
+//     (uint64_t z[static 9], uint64_t x[static 9], uint64_t y[static 9]);
+//
+// Standard x86-64 ABI: RDI = z, RSI = x, RDX = y
+// ----------------------------------------------------------------------------
+
+
+        .globl  bignum_add_p521
+        .text
+
+#define z %rdi
+#define x %rsi
+#define y %rdx
+
+#define d0 %rax
+#define d1 %rcx
+#define d2 %r8
+#define d3 %r9
+#define d4 %r10
+#define d5 %r11
+#define d6 %r12
+#define d7 %rbx
+
+// Re-use the input pointers as other variables once safe to do so
+
+#define d8 %rsi
+#define m %rdx
+
+
+
+bignum_add_p521:
+
+// Save more registers to play with
+
+        pushq   %rbx
+        pushq   %r12
+
+// Force carry-in to get s = [d8;d7;d6;d5;d4;d3;d2;d1;d0] = x + y + 1.
+// We ignore the carry-out, assuming inputs are reduced so there is none.
+
+        stc
+        movq    (x), d0
+        adcq    (y), d0
+        movq    8(x), d1
+        adcq    8(y), d1
+        movq    16(x), d2
+        adcq    16(y), d2
+        movq    24(x), d3
+        adcq    24(y), d3
+        movq    32(x), d4
+        adcq    32(y), d4
+        movq    40(x), d5
+        adcq    40(y), d5
+        movq    48(x), d6
+        adcq    48(y), d6
+        movq    56(x), d7
+        adcq    56(y), d7
+        movq    64(x), d8
+        adcq    64(y), d8
+
+// Now x + y >= p_521 <=> s = x + y + 1 >= 2^521
+// Make m = 512 * [x + y >= p_521]
+
+        movq    $512, m
+        andq    d8, m
+
+// Now if x + y >= p_521, we want (x + y) - p_521 = s - 2^521
+// while otherwise we want x + y = s - 1
+// We use the mask m both as an operand and to generate the dual carry
+// Write back the results as generated
+
+        cmpq    $512, m
+
+        sbbq    $0, d0
+        movq    d0, (z)
+        sbbq    $0, d1
+        movq    d1, 8(z)
+        sbbq    $0, d2
+        movq    d2, 16(z)
+        sbbq    $0, d3
+        movq    d3, 24(z)
+        sbbq    $0, d4
+        movq    d4, 32(z)
+        sbbq    $0, d5
+        movq    d5, 40(z)
+        sbbq    $0, d6
+        movq    d6, 48(z)
+        sbbq    $0, d7
+        movq    d7, 56(z)
+        sbbq    m, d8
+        movq    d8, 64(z)
+
+// Restore registers and return
+
+        popq    %r12
+        popq    %rbx
+
+        ret
+
+#if defined(__linux__) && defined(__ELF__)
+.section .note.GNU-stack,"",%progbits
+#endif
diff --git a/x86_att/p521/bignum_cmul_p521.S b/x86_att/p521/bignum_cmul_p521.S
new file mode 100644
index 000000000..3a5042c30
--- /dev/null
+++ b/x86_att/p521/bignum_cmul_p521.S
@@ -0,0 +1,167 @@
+/*
+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License").
+ * You may not use this file except in compliance with the License.
+ * A copy of the License is located at
+ *
+ *  http://aws.amazon.com/apache2.0
+ *
+ * or in the "LICENSE" file accompanying this file. This file is distributed
+ * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
+ * express or implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ */
+
+// ----------------------------------------------------------------------------
+// Multiply by a single word modulo p_521, z := (c * x) mod p_521, assuming
+// x reduced
+// Inputs c, x[9]; output z[9]
+//
+//    extern void bignum_cmul_p521
+//     (uint64_t z[static 9], uint64_t c, uint64_t x[static 9]);
+//
+// Standard x86-64 ABI: RDI = z, RSI = c, RDX = x
+// ----------------------------------------------------------------------------
+
+
+        .globl  bignum_cmul_p521
+        .text
+
+#define z %rdi
+
+// Temporarily moved here for initial multiply
+
+#define x %rcx
+
+// Likewise this is thrown away after initial multiply
+
+#define c %rdx
+#define cshort %edx
+
+#define a %rax
+#define dd %rax
+
+// Digits: last one aliased to the local x pointer that's no longer needed
+
+#define d0 %rsi
+#define d1 %r8
+#define d2 %r9
+#define d3 %r10
+#define d4 %r11
+#define d5 %rbx
+#define d6 %rbp
+#define d7 %r12
+#define d8 %r13
+#define d9 %rcx
+
+// Same as d9
+
+#define h d9
+
+bignum_cmul_p521:
+
+// Save additional registers to use
+
+                pushq   %rbx
+                pushq   %rbp
+                pushq   %r12
+                pushq   %r13
+
+// Shuffle inputs (since we want the multiplier in %rdx)
+
+                movq    %rdx, x
+                movq    %rsi, c
+
+// Multiply as [d9; ...; d0] = c * x.
+
+                mulxq   (x), d0, d1
+                mulxq   8(x), a, d2
+                addq    a, d1
+                mulxq   16(x), a, d3
+                adcq    a, d2
+                mulxq   24(x), a, d4
+                adcq    a, d3
+                mulxq   32(x), a, d5
+                adcq    a, d4
+                mulxq   40(x), a, d6
+                adcq    a, d5
+                mulxq   48(x), a, d7
+                adcq    a, d6
+                mulxq   56(x), a, d8
+                adcq    a, d7
+                mulxq   64(x), a, d9
+                adcq    a, d8
+                adcq    $0, d9
+
+// Create an AND "dd" of digits d7,...,d1, a computation we hope will
+// get nicely interleaved with the multiplication chain above.
+// From the point of view of architectural dependencies we have to
+// bunch it up here since AND destroys the flags and we overwrite the
+// register used as a stage temporary variable for the multiplications.
+
+                movq    d1, dd
+                andq    d2, dd
+                andq    d3, dd
+                andq    d4, dd
+                andq    d5, dd
+                andq    d6, dd
+                andq    d7, dd
+
+// Extract the high part h==d9 and mask off the low part l = [d8;d7;...;d0]
+// but stuff d8 with 1 bits at the left to ease a comparison below
+
+                shldq   $55, d8, h
+                orq     $~0x1FF, d8
+
+// Decide whether h + l >= p_521 <=> h + l + 1 >= 2^521. Since this can only
+// happen if digits d7,...d1 are all 1s, we use the AND of them "dd" to
+// condense the carry chain, and since we stuffed 1 bits into d8 we get
+// the result in CF without an additional comparison. Hereafter we use c = 0.
+// Since x was assumed reduced, h cannot be maximal, so the "lea" is safe,
+// i.e. does not carry or wrap round.
+
+                leaq    1(h), c
+                addq    d0, c
+                movl    $0, cshort
+                adcq    c, dd
+                movq    d8, a
+                adcq    c, a
+
+// Now if CF is set we want (h + l) - p_521 = (h + l + 1) - 2^521
+// while otherwise we want just h + l. So mask h + l + CF to 521 bits.
+// This masking also gets rid of the stuffing with 1s we did above.
+// Write back the digits as they are generated.
+
+                adcq    h, d0
+                movq    d0, (z)
+                adcq    c, d1
+                movq    d1, 8(z)
+                adcq    c, d2
+                movq    d2, 16(z)
+                adcq    c, d3
+                movq    d3, 24(z)
+                adcq    c, d4
+                movq    d4, 32(z)
+                adcq    c, d5
+                movq    d5, 40(z)
+                adcq    c, d6
+                movq    d6, 48(z)
+                adcq    c, d7
+                movq    d7, 56(z)
+                adcq    c, d8
+                andq    $0x1FF, d8
+                movq    d8, 64(z)
+
+// Restore registers and return
+
+                popq    %r13
+                popq    %r12
+                popq    %rbp
+                popq    %rbx
+
+                ret
+
+#if defined(__linux__) && defined(__ELF__)
+.section .note.GNU-stack,"",%progbits
+#endif
diff --git a/x86_att/p521/bignum_deamont_p521.S b/x86_att/p521/bignum_deamont_p521.S
new file mode 100644
index 000000000..c6e3e3e0f
--- /dev/null
+++ b/x86_att/p521/bignum_deamont_p521.S
@@ -0,0 +1,139 @@
+/*
+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License").
+ * You may not use this file except in compliance with the License.
+ * A copy of the License is located at
+ *
+ *  http://aws.amazon.com/apache2.0
+ *
+ * or in the "LICENSE" file accompanying this file. This file is distributed
+ * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
+ * express or implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ */
+
+// ----------------------------------------------------------------------------
+// Convert from Montgomery form z := (x / 2^576) mod p_521
+// Input x[9]; output z[9]
+//
+//    extern void bignum_deamont_p521
+//     (uint64_t z[static 9], uint64_t x[static 9]);
+//
+// Convert a 9-digit bignum x out of its (optionally almost) Montgomery form,
+// "almost" meaning any 9-digit input will work, with no range restriction.
+//
+// Standard x86-64 ABI: RDI = z, RSI = x
+// ----------------------------------------------------------------------------
+
+
+        .globl  bignum_deamont_p521
+        .text
+
+#define z %rdi
+#define x %rsi
+
+#define c %rax
+#define h %rax
+#define l %rbx
+
+#define d0 %rdx
+#define d1 %rcx
+#define d2 %r8
+#define d3 %r9
+#define d4 %r10
+#define d5 %r11
+#define d6 %r12
+#define d7 %r13
+#define d8 %rbp
+
+bignum_deamont_p521:
+
+// Save more registers to play with
+
+        pushq   %rbx
+        pushq   %r12
+        pushq   %r13
+        pushq   %rbp
+
+// Stash the lowest 55 bits at the top of c, then shift the whole 576-bit
+// input right by 9*64 - 521 = 576 - 521 = 55 bits.
+
+        movq    (x), d0
+        movq    d0, c
+        shlq    $9, c
+        movq    8(x), d1
+        shrdq   $55, d1, d0
+        movq    16(x), d2
+        shrdq   $55, d2, d1
+        movq    24(x), d3
+        shrdq   $55, d3, d2
+        movq    32(x), d4
+        shrdq   $55, d4, d3
+        movq    40(x), d5
+        shrdq   $55, d5, d4
+        movq    48(x), d6
+        shrdq   $55, d6, d5
+        movq    56(x), d7
+        shrdq   $55, d7, d6
+        movq    64(x), d8
+        shrdq   $55, d8, d7
+        shrq    $55, d8
+
+// Now writing x = 2^55 * h + l (so here [d8;..d0] = h and c = 2^9 * l)
+// we want (h + 2^{521-55} * l) mod p_521 = s mod p_521. Since s < 2 * p_521
+// this is just "if s >= p_521 then s - p_521 else s". First get
+// s + 1, but pad up the top to get a top-bit carry-out from it, so now
+// CF <=> s + 1 >= 2^521 <=> s >= p_521, while the digits [d8;...d0] are
+// now s + 1 except for bits above 521.
+
+        movq    c, l
+        shrq    $55, h
+        shlq    $9, l
+        orq     $~0x1FF, d8
+        addq    $1, d0
+        adcq    $0, d1
+        adcq    $0, d2
+        adcq    $0, d3
+        adcq    $0, d4
+        adcq    $0, d5
+        adcq    $0, d6
+        adcq    l, d7
+        adcq    h, d8
+
+// We want "if CF then (s + 1) - 2^521 else (s + 1) - 1" so subtract ~CF
+// and mask to 521 bits, writing digits back as they are created.
+
+        cmc
+        sbbq    $0, d0
+        movq    d0, (z)
+        sbbq    $0, d1
+        movq    d1, 8(z)
+        sbbq    $0, d2
+        movq    d2, 16(z)
+        sbbq    $0, d3
+        movq    d3, 24(z)
+        sbbq    $0, d4
+        movq    d4, 32(z)
+        sbbq    $0, d5
+        movq    d5, 40(z)
+        sbbq    $0, d6
+        movq    d6, 48(z)
+        sbbq    $0, d7
+        movq    d7, 56(z)
+        sbbq    $0, d8
+        andq    $0x1FF, d8
+        movq    d8, 64(z)
+
+// Restore registers and return
+
+        popq    %rbp
+        popq    %r13
+        popq    %r12
+        popq    %rbx
+
+        ret
+
+#if defined(__linux__) && defined(__ELF__)
+.section .note.GNU-stack,"",%progbits
+#endif
diff --git a/x86_att/p521/bignum_demont_p521.S b/x86_att/p521/bignum_demont_p521.S
new file mode 100644
index 000000000..66e4707c2
--- /dev/null
+++ b/x86_att/p521/bignum_demont_p521.S
@@ -0,0 +1,88 @@
+/*
+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License").
+ * You may not use this file except in compliance with the License.
+ * A copy of the License is located at
+ *
+ *  http://aws.amazon.com/apache2.0
+ *
+ * or in the "LICENSE" file accompanying this file. This file is distributed
+ * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
+ * express or implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ */
+
+// ----------------------------------------------------------------------------
+// Convert from Montgomery form z := (x / 2^576) mod p_521, assuming x reduced
+// Input x[9]; output z[9]
+//
+//    extern void bignum_demont_p521
+//     (uint64_t z[static 9], uint64_t x[static 9]);
+//
+// This assumes the input is < p_521 for correctness. If this is not the case,
+// use the variant "bignum_deamont_p521" instead.
+//
+// Standard x86-64 ABI: RDI = z, RSI = x
+// ----------------------------------------------------------------------------
+
+
+        .globl  bignum_demont_p521
+        .text
+
+#define z %rdi
+#define x %rsi
+
+// Rotating (aliased) registers for the digits
+
+#define c %rax
+#define d0 %rdx
+#define d1 %rcx
+
+#define d2 %rdx
+#define d3 %rcx
+#define d4 %rdx
+#define d5 %rcx
+#define d6 %rdx
+#define d7 %rcx
+#define d8 %rdx
+
+bignum_demont_p521:
+
+// Rotate, as a 521-bit quantity, by 9*64 - 521 = 55 bits right.
+
+        movq    (x), d0
+        movq    d0, c
+        movq    8(x), d1
+        shrdq   $55, d1, d0
+        movq    d0, (z)
+        movq    16(x), d2
+        shrdq   $55, d2, d1
+        movq    d1, 8(z)
+        movq    24(x), d3
+        shrdq   $55, d3, d2
+        shlq    $9, c
+        movq    d2, 16(z)
+        movq    32(x), d4
+        shrdq   $55, d4, d3
+        movq    d3, 24(z)
+        movq    40(x), d5
+        shrdq   $55, d5, d4
+        movq    d4, 32(z)
+        movq    48(x), d6
+        shrdq   $55, d6, d5
+        movq    d5, 40(z)
+        movq    56(x), d7
+        shrdq   $55, d7, d6
+        movq    d6, 48(z)
+        movq    64(x), d8
+        orq     c, d8
+        shrdq   $55, d8, d7
+        movq    d7, 56(z)
+        shrq    $55, d8
+        movq    d8, 64(z)
+        ret
+
+#if defined(__linux__) && defined(__ELF__)
+.section .note.GNU-stack,"",%progbits
+#endif
diff --git a/x86_att/p521/bignum_double_p521.S b/x86_att/p521/bignum_double_p521.S
new file mode 100644
index 000000000..a106ab2e2
--- /dev/null
+++ b/x86_att/p521/bignum_double_p521.S
@@ -0,0 +1,90 @@
+/*
+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License").
+ * You may not use this file except in compliance with the License.
+ * A copy of the License is located at
+ *
+ *  http://aws.amazon.com/apache2.0
+ *
+ * or in the "LICENSE" file accompanying this file. This file is distributed
+ * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
+ * express or implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ */
+
+// ----------------------------------------------------------------------------
+// Double modulo p_521, z := (2 * x) mod p_521, assuming x reduced
+// Input x[9]; output z[9]
+//
+//    extern void bignum_double_p521
+//     (uint64_t z[static 9], uint64_t x[static 9]);
+//
+// Standard x86-64 ABI: RDI = z, RSI = x
+// ----------------------------------------------------------------------------
+
+
+        .globl  bignum_double_p521
+        .text
+
+#define z %rdi
+#define x %rsi
+
+#define a %rax
+#define c %rcx
+
+
+
+bignum_double_p521:
+
+// We can decide whether 2 * x >= p_521 just by 2 * x >= 2^521, which
+// as we assume x < p_521 amounts to looking at bit 8 of the top word
+
+        movq    64(x), c
+        btq     $8, c
+
+// Now if 2 * x >= p_521 we want 2 * x - p_521 = (2 * x + 1) - 2^521
+// and otherwise just 2 * x. Feed in the condition as the carry bit
+// to get 2 * x + [2 * x >= p_521] then just mask it off to 521 bits.
+
+        movq    (x), a
+        adcq    a, a
+        movq    a, (z)
+
+        movq    8(x), a
+        adcq    a, a
+        movq    a, 8(z)
+
+        movq    16(x), a
+        adcq    a, a
+        movq    a, 16(z)
+
+        movq    24(x), a
+        adcq    a, a
+        movq    a, 24(z)
+
+        movq    32(x), a
+        adcq    a, a
+        movq    a, 32(z)
+
+        movq    40(x), a
+        adcq    a, a
+        movq    a, 40(z)
+
+        movq    48(x), a
+        adcq    a, a
+        movq    a, 48(z)
+
+        movq    56(x), a
+        adcq    a, a
+        movq    a, 56(z)
+
+        adcq    c, c
+        andq    $0x1FF, c
+        movq    c, 64(z)
+
+        ret
+
+#if defined(__linux__) && defined(__ELF__)
+.section .note.GNU-stack,"",%progbits
+#endif
diff --git a/x86_att/p521/bignum_half_p521.S b/x86_att/p521/bignum_half_p521.S
new file mode 100644
index 000000000..c5d62a302
--- /dev/null
+++ b/x86_att/p521/bignum_half_p521.S
@@ -0,0 +1,99 @@
+/*
+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License").
+ * You may not use this file except in compliance with the License.
+ * A copy of the License is located at
+ *
+ *  http://aws.amazon.com/apache2.0
+ *
+ * or in the "LICENSE" file accompanying this file. This file is distributed
+ * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
+ * express or implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ */
+
+// ----------------------------------------------------------------------------
+// Halve modulo p_521, z := (x / 2) mod p_521, assuming x reduced
+// Input x[9]; output z[9]
+//
+//    extern void bignum_half_p521
+//     (uint64_t z[static 9], uint64_t x[static 9]);
+//
+// Standard x86-64 ABI: RDI = z, RSI = x
+// ----------------------------------------------------------------------------
+
+
+        .globl  bignum_half_p521
+        .text
+
+#define z %rdi
+#define x %rsi
+
+// We use distinct variables for clarity, but these are heavily aliased
+
+#define d0 %rcx
+#define d1 %rdx
+#define d2 %rcx
+#define d3 %rdx
+#define d4 %rcx
+#define d5 %rdx
+#define d6 %rcx
+#define d7 %rdx
+#define d8 %rcx
+#define a %rax
+#define ashort %eax
+
+
+
+bignum_half_p521:
+
+// We do a 521-bit rotation one bit right, since 2^521 == 1 (mod p_521)
+
+                movq    (x), d0
+                movl    $1, ashort
+                andq    d0, a
+
+                movq    8(x), d1
+                shrdq   $1, d1, d0
+                movq    d0, (z)
+
+                movq    16(x), d2
+                shrdq   $1, d2, d1
+                movq    d1, 8(z)
+
+                movq    24(x), d3
+                shrdq   $1, d3, d2
+                movq    d2, 16(z)
+
+                movq    32(x), d4
+                shrdq   $1, d4, d3
+                movq    d3, 24(z)
+
+                movq    40(x), d5
+                shrdq   $1, d5, d4
+                movq    d4, 32(z)
+
+                movq    48(x), d6
+                shrdq   $1, d6, d5
+                movq    d5, 40(z)
+
+                movq    56(x), d7
+                shrdq   $1, d7, d6
+                movq    d6, 48(z)
+
+                movq    64(x), d8
+                shrdq   $1, d8, d7
+                movq    d7, 56(z)
+
+                shlq    $55, d8
+                shrdq   $56, a, d8
+                movq    d8, 64(z)
+
+// Return
+
+                ret
+
+#if defined(__linux__) && defined(__ELF__)
+.section .note.GNU-stack,"",%progbits
+#endif
diff --git a/x86_att/p521/bignum_mod_p521_9.S b/x86_att/p521/bignum_mod_p521_9.S
new file mode 100644
index 000000000..388c0c63f
--- /dev/null
+++ b/x86_att/p521/bignum_mod_p521_9.S
@@ -0,0 +1,116 @@
+/*
+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License").
+ * You may not use this file except in compliance with the License.
+ * A copy of the License is located at
+ *
+ *  http://aws.amazon.com/apache2.0
+ *
+ * or in the "LICENSE" file accompanying this file. This file is distributed
+ * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
+ * express or implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ */
+
+// ----------------------------------------------------------------------------
+// Reduce modulo field characteristic, z := x mod p_521
+// Input x[9]; output z[9]
+//
+//    extern void bignum_mod_p521_9
+//     (uint64_t z[static 9], uint64_t x[static 9]);
+//
+// Standard x86-64 ABI: RDI = z, RSI = x
+// ----------------------------------------------------------------------------
+
+
+        .globl  bignum_mod_p521_9
+        .text
+
+#define z %rdi
+#define x %rsi
+
+#define d0 %rax
+#define d1 %rcx
+#define d2 %r8
+#define d3 %r9
+#define d4 %r10
+#define d5 %r11
+#define d6 %rbx
+
+#define d8 %rdx
+
+#define d8short %edx
+
+// Re-use the input pointer as other variable once safe to do so
+
+#define d7 %rsi
+
+bignum_mod_p521_9:
+
+// Save one more register
+
+        pushq   %rbx
+
+// Separate out the input into x = 2^521 * H + L, so that x mod p_521 =
+// (H + L) mod p_521 = if H + L >= p_521 then H + L - p_521 else H + L.
+
+        movq    64(x), d0
+        movl    $0x1FF, d8short
+        andq    d0, d8
+        shrq    $9, d0
+
+// Force carry-in to get s = [d8;d7;d6;d5;d4;d3;d2;d1;d0] = H + L + 1.
+
+        stc
+        adcq    (x), d0
+        movq    8(x), d1
+        adcq    $0, d1
+        movq    16(x), d2
+        adcq    $0, d2
+        movq    24(x), d3
+        adcq    $0, d3
+        movq    32(x), d4
+        adcq    $0, d4
+        movq    40(x), d5
+        adcq    $0, d5
+        movq    48(x), d6
+        adcq    $0, d6
+        movq    56(x), d7
+        adcq    $0, d7
+        adcq    $0, d8
+
+// Set CF <=> s < 2^521 <=> H + L < p_521, so that if CF is set
+// we want H + L = s - 1, otherwise (H + L) - p_521 = s - 2^521.
+// This is done with just s - CF then masking to 521 bits.
+
+        cmpq    $512, d8
+
+        sbbq    $0, d0
+        movq    d0, (z)
+        sbbq    $0, d1
+        movq    d1, 8(z)
+        sbbq    $0, d2
+        movq    d2, 16(z)
+        sbbq    $0, d3
+        movq    d3, 24(z)
+        sbbq    $0, d4
+        movq    d4, 32(z)
+        sbbq    $0, d5
+        movq    d5, 40(z)
+        sbbq    $0, d6
+        movq    d6, 48(z)
+        sbbq    $0, d7
+        movq    d7, 56(z)
+        sbbq    $0, d8
+        andq    $0x1FF, d8
+        movq    d8, 64(z)
+
+// Restore register
+
+        popq    %rbx
+        ret
+
+#if defined(__linux__) && defined(__ELF__)
+.section .note.GNU-stack,"",%progbits
+#endif
diff --git a/x86_att/p521/bignum_montsqr_p521.S b/x86_att/p521/bignum_montsqr_p521.S
new file mode 100644
index 000000000..45c89145b
--- /dev/null
+++ b/x86_att/p521/bignum_montsqr_p521.S
@@ -0,0 +1,316 @@
+/*
+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License").
+ * You may not use this file except in compliance with the License.
+ * A copy of the License is located at
+ *
+ *  http://aws.amazon.com/apache2.0
+ *
+ * or in the "LICENSE" file accompanying this file. This file is distributed
+ * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
+ * express or implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ */
+
+// ----------------------------------------------------------------------------
+// Montgomery square, z := (x^2 / 2^576) mod p_521
+// Input x[9]; output z[9]
+//
+//    extern void bignum_montsqr_p521
+//     (uint64_t z[static 9], uint64_t x[static 9]);
+//
+// Does z := (x^2 / 2^576) mod p_521, assuming x < p_521. This means the
+// Montgomery base is the "native size" 2^{9*64} = 2^576; since p_521 is
+// a Mersenne prime the basic modular squaring bignum_sqr_p521 can be
+// considered a Montgomery operation to base 2^521.
+//
+// Standard x86-64 ABI: RDI = z, RSI = x
+// ----------------------------------------------------------------------------
+
+
+        .globl  bignum_montsqr_p521
+        .text
+
+#define z %rdi
+#define x %rsi
+
+// A zero register
+
+#define zero %rbp
+#define zeroe %ebp
+
+// mulpadd (high,low,i) adds %rdx * x[i] to a register-pair (high,low)
+// maintaining consistent double-carrying with adcx and adox,
+// using %rax and %rcx as temporaries.
+
+#define mulpadd(high,low,I)             \
+        mulxq   I(x), %rax, %rcx ;        \
+        adcxq   %rax, low ;               \
+        adoxq   %rcx, high
+
+// mulpade (hight,low,i) adds %rdx * x[i] to a register-pair (high,low)
+// maintaining consistent double-carrying with adcx and adox,
+// using %rax as a temporary, assuming high created from scratch
+// and that zero has value zero.
+
+#define mulpade(high,low,I)             \
+        mulxq   I(x), %rax, high ;       \
+        adcxq   %rax, low ;               \
+        adoxq   zero, high
+
+bignum_montsqr_p521:
+
+// Save more registers to play with
+
+        pushq   %rbp
+        pushq   %r12
+        pushq   %r13
+        pushq   %r14
+        pushq   %r15
+
+// Do a basic 8x8 squaring writing back z[0..7] but keeping the
+// top half in the usual rotating register window %r15,...,%r8. Except
+// for the lack of full writeback this is the same as bignum_sqr_8_16.
+
+        xorl    zeroe, zeroe
+
+        movq    (x), %rdx
+        mulxq   8(x), %r9, %rax
+        movq    %r9, 8(z)
+        mulxq   16(x), %r10, %rcx
+        adcxq   %rax, %r10
+        movq    %r10, 16(z)
+        mulxq   24(x), %r11, %rax
+        adcxq   %rcx, %r11
+        mulxq   32(x), %r12, %rcx
+        adcxq   %rax, %r12
+        mulxq   40(x), %r13, %rax
+        adcxq   %rcx, %r13
+        mulxq   48(x), %r14, %rcx
+        adcxq   %rax, %r14
+        mulxq   56(x), %r15, %r8
+        adcxq   %rcx, %r15
+        adcxq   zero, %r8
+
+        xorl    zeroe, zeroe
+        movq    8(x), %rdx
+        mulpadd(%r12,%r11,16)
+        movq    %r11, 24(z)
+        mulpadd(%r13,%r12,24)
+        movq    %r12, 32(z)
+        mulpadd(%r14,%r13,32)
+        mulpadd(%r15,%r14,40)
+        mulpadd(%r8,%r15,48)
+        mulpade(%r9,%r8,56)
+        movq    32(x), %rdx
+        mulpade(%r10,%r9,40)
+        adcxq   zero, %r10
+
+        xorl    zeroe, zeroe
+        movq    16(x), %rdx
+        mulpadd(%r14,%r13,24)
+        movq    %r13, 40(z)
+        mulpadd(%r15,%r14,32)
+        movq    %r14, 48(z)
+        mulpadd(%r8,%r15,40)
+        mulpadd(%r9,%r8,48)
+        mulpadd(%r10,%r9,56)
+        movq    48(x), %rdx
+        mulpade(%r11,%r10,32)
+        mulpade(%r12,%r11,40)
+        adcxq   zero, %r12
+
+        xorl    zeroe, zeroe
+        movq    24(x), %rdx
+        mulpadd(%r8,%r15,32)
+        movq    %r15, 56(z)
+        mulpadd(%r9,%r8,40)
+        mulpadd(%r10,%r9,48)
+        mulpadd(%r11,%r10,56)
+        movq    56(x), %rdx
+        mulpadd(%r12,%r11,32)
+        mulpade(%r13,%r12,40)
+        mulpade(%r14,%r13,48)
+        adcxq   zero, %r14
+
+        xorl    zeroe, zeroe
+        movq    (x), %rdx
+        mulxq   %rdx, %rax, %rcx
+        movq    %rax, (z)
+        movq    8(z), %rax
+        adcxq   %rax, %rax
+        adoxq   %rcx, %rax
+        movq    %rax, 8(z)
+
+        movq    16(z), %rax
+        movq    8(x), %rdx
+        mulxq   %rdx, %rdx, %rcx
+        adcxq   %rax, %rax
+        adoxq   %rdx, %rax
+        movq    %rax, 16(z)
+        movq    24(z), %rax
+        adcxq   %rax, %rax
+        adoxq   %rcx, %rax
+        movq    %rax, 24(z)
+
+        movq    32(z), %rax
+        movq    16(x), %rdx
+        mulxq   %rdx, %rdx, %rcx
+        adcxq   %rax, %rax
+        adoxq   %rdx, %rax
+        movq    %rax, 32(z)
+        movq    40(z), %rax
+        adcxq   %rax, %rax
+        adoxq   %rcx, %rax
+        movq    %rax, 40(z)
+
+        movq    48(z), %rax
+        movq    24(x), %rdx
+        mulxq   %rdx, %rdx, %rcx
+        adcxq   %rax, %rax
+        adoxq   %rdx, %rax
+        movq    %rax, 48(z)
+        movq    56(z), %rax
+        adcxq   %rax, %rax
+        adoxq   %rcx, %rax
+        movq    %rax, 56(z)
+
+        movq    32(x), %rdx
+        mulxq   %rdx, %rdx, %rcx
+        adcxq   %r8, %r8
+        adoxq   %rdx, %r8
+        adcxq   %r9, %r9
+        adoxq   %rcx, %r9
+
+        movq    40(x), %rdx
+        mulxq   %rdx, %rdx, %rcx
+        adcxq   %r10, %r10
+        adoxq   %rdx, %r10
+        adcxq   %r11, %r11
+        adoxq   %rcx, %r11
+
+        movq    48(x), %rdx
+        mulxq   %rdx, %rdx, %rcx
+        adcxq   %r12, %r12
+        adoxq   %rdx, %r12
+        adcxq   %r13, %r13
+        adoxq   %rcx, %r13
+
+        movq    56(x), %rdx
+        mulxq   %rdx, %rdx, %r15
+        adcxq   %r14, %r14
+        adoxq   %rdx, %r14
+        adcxq   zero, %r15
+        adoxq   zero, %r15
+
+// Augment the high part with the contribution from the top little word C.
+// If we write the input as 2^512 * C + x then we are otherwise just doing
+// x^2, so we need to add to the high part 2^512 * C^2 + (2 * C) * x.
+// The initial doubling add of C also clears the CF and OF flags as desired.
+// We extend the window now to the 9-element %rbp,%r15,%r14,...,%r8.
+
+        movq    64(x), %rdx
+        movq    %rdx, %rbp
+        imulq   %rbp, %rbp
+        addq    %rdx, %rdx
+        mulpadd(%r9,%r8,0)
+        mulpadd(%r10,%r9,8)
+        mulpadd(%r11,%r10,16)
+        mulpadd(%r12,%r11,24)
+        mulpadd(%r13,%r12,32)
+        mulpadd(%r14,%r13,40)
+        mulpadd(%r15,%r14,48)
+        mulxq  56(x), %rax, %rcx
+        adcxq  %rax, %r15
+        adoxq  %rcx, %rbp
+        adcq   $0, %rbp
+
+// Rotate the upper portion right 9 bits since 2^512 == 2^-9 (mod p_521)
+// Let rotated result %rbp,%r15,%r14,...,%r8 be h (high) and z[0..7] be l (low)
+
+        movq    %r8, %rax
+        andq    $0x1FF, %rax
+        shrdq   $9, %r9, %r8
+        shrdq   $9, %r10, %r9
+        shrdq   $9, %r11, %r10
+        shrdq   $9, %r12, %r11
+        shrdq   $9, %r13, %r12
+        shrdq   $9, %r14, %r13
+        shrdq   $9, %r15, %r14
+        shrdq   $9, %rbp, %r15
+        shrq    $9, %rbp
+        addq    %rax, %rbp
+
+// Force carry-in then add to get s = h + l + 1
+// but actually add all 1s in the top 53 bits to get simple carry out
+
+        stc
+        adcq    (z), %r8
+        adcq    8(z), %r9
+        adcq    16(z), %r10
+        adcq    24(z), %r11
+        adcq    32(z), %r12
+        adcq    40(z), %r13
+        adcq    48(z), %r14
+        adcq    56(z), %r15
+        adcq    $~0x1FF, %rbp
+
+// Now CF is set <=> h + l + 1 >= 2^521 <=> h + l >= p_521,
+// in which case the lower 521 bits are already right. Otherwise if
+// CF is clear, we want to subtract 1. Hence suntract the complement
+// of the carry flag then mask the top word, which scrubs the
+// padding in either case.
+
+        cmc
+        sbbq    $0, %r8
+        sbbq    $0, %r9
+        sbbq    $0, %r10
+        sbbq    $0, %r11
+        sbbq    $0, %r12
+        sbbq    $0, %r13
+        sbbq    $0, %r14
+        sbbq    $0, %r15
+        sbbq    $0, %rbp
+        andq    $0x1FF, %rbp
+
+// So far, this has been the same as a pure modular squaring.
+// Now finally the Montgomery ingredient, which is just a 521-bit
+// rotation by 9*64 - 521 = 55 bits right. Write digits back as
+// they are created.
+
+        movq    %r8, %rax
+        shrdq   $55, %r9, %r8
+        movq    %r8, (z)
+        shrdq   $55, %r10, %r9
+        movq    %r9, 8(z)
+        shrdq   $55, %r11, %r10
+        shlq    $9, %rax
+        movq    %r10, 16(z)
+        shrdq   $55, %r12, %r11
+        movq    %r11, 24(z)
+        shrdq   $55, %r13, %r12
+        movq    %r12, 32(z)
+        orq     %rax, %rbp
+        shrdq   $55, %r14, %r13
+        movq    %r13, 40(z)
+        shrdq   $55, %r15, %r14
+        movq    %r14, 48(z)
+        shrdq   $55, %rbp, %r15
+        movq    %r15, 56(z)
+        shrq    $55, %rbp
+        movq    %rbp, 64(z)
+
+// Restore registers and return
+
+        popq    %r15
+        popq    %r14
+        popq    %r13
+        popq    %r12
+        popq    %rbp
+
+        ret
+
+#if defined(__linux__) && defined(__ELF__)
+.section .note.GNU-stack,"",%progbits
+#endif
diff --git a/x86_att/p521/bignum_neg_p521.S b/x86_att/p521/bignum_neg_p521.S
new file mode 100644
index 000000000..d00006f4f
--- /dev/null
+++ b/x86_att/p521/bignum_neg_p521.S
@@ -0,0 +1,98 @@
+/*
+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License").
+ * You may not use this file except in compliance with the License.
+ * A copy of the License is located at
+ *
+ *  http://aws.amazon.com/apache2.0
+ *
+ * or in the "LICENSE" file accompanying this file. This file is distributed
+ * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
+ * express or implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ */
+
+// ----------------------------------------------------------------------------
+// Negate modulo p_521, z := (-x) mod p_521, assuming x reduced
+// Input x[9]; output z[9]
+//
+//    extern void bignum_neg_p521 (uint64_t z[static 9], uint64_t x[static 9]);
+//
+// Standard x86-64 ABI: RDI = z, RSI = x
+// ----------------------------------------------------------------------------
+
+
+        .globl  bignum_neg_p521
+        .text
+
+#define z %rdi
+#define x %rsi
+
+#define p %rax
+#define d0 %rcx
+#define d1 %rdx
+#define d2 %r8
+#define d3 %r9
+#define d4 %r10
+#define d5 %r11
+
+bignum_neg_p521:
+
+// Load most inputs (into the limited registers) and OR all of them to get p
+
+                movq    (x), d0
+                movq    d0, p
+                movq    8(x), d1
+                orq     d1, p
+                movq    16(x), d2
+                orq     d2, p
+                movq    24(x), d3
+                orq     d3, p
+                movq    32(x), d4
+                orq     d4, p
+                movq    40(x), d5
+                orq     d5, p
+                orq     48(x), p
+                orq     56(x), p
+                orq     64(x), p
+
+// Turn p into a bitmask for "input is nonzero", so that we avoid doing
+// -0 = p_521 and hence maintain strict modular reduction
+
+                negq    p
+                sbbq    p, p
+
+// Since p_521 is all 1s, the subtraction is just an exclusive-or with p
+// to give an optional inversion, with a slight fiddle for the top digit.
+
+                xorq    p, d0
+                movq    d0, (z)
+                xorq    p, d1
+                movq    d1, 8(z)
+                xorq    p, d2
+                movq    d2, 16(z)
+                xorq    p, d3
+                movq    d3, 24(z)
+                xorq    p, d4
+                movq    d4, 32(z)
+                xorq    p, d5
+                movq    d5, 40(z)
+                movq    48(x), d0
+                xorq    p, d0
+                movq    d0, 48(z)
+                movq    56(x), d1
+                xorq    p, d1
+                movq    d1, 56(z)
+                movq    64(x), d2
+                andq    $0x1FF, p
+                xorq    p, d2
+                movq    d2, 64(z)
+
+// Return
+
+                ret
+
+#if defined(__linux__) && defined(__ELF__)
+.section .note.GNU-stack,"",%progbits
+#endif
diff --git a/x86_att/p521/bignum_optneg_p521.S b/x86_att/p521/bignum_optneg_p521.S
new file mode 100644
index 000000000..31db989b3
--- /dev/null
+++ b/x86_att/p521/bignum_optneg_p521.S
@@ -0,0 +1,102 @@
+/*
+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License").
+ * You may not use this file except in compliance with the License.
+ * A copy of the License is located at
+ *
+ *  http://aws.amazon.com/apache2.0
+ *
+ * or in the "LICENSE" file accompanying this file. This file is distributed
+ * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
+ * express or implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ */
+
+// ----------------------------------------------------------------------------
+// Optionally negate modulo p_521, z := (-x) mod p_521 (if p nonzero) or
+// z := x (if p zero), assuming x reduced
+// Inputs p, x[9]; output z[9]
+//
+//    extern void bignum_optneg_p521
+//      (uint64_t z[static 9], uint64_t p, uint64_t x[static 9]);
+//
+// Standard x86-64 ABI: RDI = z, RSI = p, RDX = x
+// ----------------------------------------------------------------------------
+
+
+        .globl  bignum_optneg_p521
+        .text
+
+#define z %rdi
+#define p %rsi
+#define x %rdx
+
+#define q %rax
+#define d0 %rcx
+#define d1 %r8
+#define d2 %r9
+#define d3 %r10
+#define d4 %r11
+
+bignum_optneg_p521:
+
+// Load most inputs (into the limited registers) and OR all of them to get q
+
+                movq    (x), d0
+                movq    d0, q
+                movq    8(x), d1
+                orq     d1, q
+                movq    16(x), d2
+                orq     d2, q
+                movq    24(x), d3
+                orq     d3, q
+                movq    32(x), d4
+                orq     d4, q
+                orq     40(x), q
+                orq     48(x), q
+                orq     56(x), q
+                orq     64(x), q
+
+// Turn q into a bitmask for "input is nonzero and p is nonzero", so that
+// we avoid doing -0 = p_521 and hence maintain strict modular reduction
+
+                negq    q
+                sbbq    q, q
+                testq   p, p
+                cmovzq  p, q
+
+// Since p_521 is all 1s, the subtraction is just an exclusive-or with q
+// to give an optional inversion, with a slight fiddle for the top digit.
+
+                xorq    q, d0
+                movq    d0, (z)
+                xorq    q, d1
+                movq    d1, 8(z)
+                xorq    q, d2
+                movq    d2, 16(z)
+                xorq    q, d3
+                movq    d3, 24(z)
+                xorq    q, d4
+                movq    d4, 32(z)
+                movq    40(x), d0
+                xorq    q, d0
+                movq    d0, 40(z)
+                movq    48(x), d1
+                xorq    q, d1
+                movq    d1, 48(z)
+                movq    56(x), d2
+                xorq    q, d2
+                movq    d2, 56(z)
+                movq    64(x), d3
+                andq    $0x1FF, q
+                xorq    q, d3
+                movq    d3, 64(z)
+
+// Return
+
+                ret
+
+#if defined(__linux__) && defined(__ELF__)
+.section .note.GNU-stack,"",%progbits
+#endif
diff --git a/x86_att/p521/bignum_sqr_p521.S b/x86_att/p521/bignum_sqr_p521.S
new file mode 100644
index 000000000..5739b881d
--- /dev/null
+++ b/x86_att/p521/bignum_sqr_p521.S
@@ -0,0 +1,292 @@
+/*
+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License").
+ * You may not use this file except in compliance with the License.
+ * A copy of the License is located at
+ *
+ *  http://aws.amazon.com/apache2.0
+ *
+ * or in the "LICENSE" file accompanying this file. This file is distributed
+ * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
+ * express or implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ */
+
+// ----------------------------------------------------------------------------
+// Square modulo p_521, z := (x^2) mod p_521, assuming x reduced
+// Input x[9]; output z[9]
+//
+//    extern void bignum_sqr_p521 (uint64_t z[static 9], uint64_t x[static 9]);
+//
+// Standard x86-64 ABI: RDI = z, RSI = x
+// ----------------------------------------------------------------------------
+
+
+        .globl  bignum_sqr_p521
+        .text
+
+#define z %rdi
+#define x %rsi
+
+// A zero register
+
+#define zero %rbp
+#define zeroe %ebp
+
+// mulpadd (high,low,i) adds %rdx * x[i] to a register-pair (high,low)
+// maintaining consistent double-carrying with adcx and adox,
+// using %rax and %rcx as temporaries.
+
+#define mulpadd(high,low,I)             \
+        mulxq   I(x), %rax, %rcx ;        \
+        adcxq   %rax, low ;               \
+        adoxq   %rcx, high
+
+// mulpade (hight,low,i) adds %rdx * x[i] to a register-pair (high,low)
+// maintaining consistent double-carrying with adcx and adox,
+// using %rax as a temporary, assuming high created from scratch
+// and that zero has value zero.
+
+#define mulpade(high,low,I)             \
+        mulxq   I(x), %rax, high ;       \
+        adcxq   %rax, low ;               \
+        adoxq   zero, high
+
+bignum_sqr_p521:
+
+// Save more registers to play with
+
+        pushq   %rbp
+        pushq   %r12
+        pushq   %r13
+        pushq   %r14
+        pushq   %r15
+
+// Do a basic 8x8 squaring writing back z[0..7] but keeping the
+// top half in the usual rotating register window %r15,...,%r8. Except
+// for the lack of full writeback this is the same as bignum_sqr_8_16.
+
+        xorl    zeroe, zeroe
+
+        movq    (x), %rdx
+        mulxq   8(x), %r9, %rax
+        movq    %r9, 8(z)
+        mulxq   16(x), %r10, %rcx
+        adcxq   %rax, %r10
+        movq    %r10, 16(z)
+        mulxq   24(x), %r11, %rax
+        adcxq   %rcx, %r11
+        mulxq   32(x), %r12, %rcx
+        adcxq   %rax, %r12
+        mulxq   40(x), %r13, %rax
+        adcxq   %rcx, %r13
+        mulxq   48(x), %r14, %rcx
+        adcxq   %rax, %r14
+        mulxq   56(x), %r15, %r8
+        adcxq   %rcx, %r15
+        adcxq   zero, %r8
+
+        xorl    zeroe, zeroe
+        movq    8(x), %rdx
+        mulpadd(%r12,%r11,16)
+        movq    %r11, 24(z)
+        mulpadd(%r13,%r12,24)
+        movq    %r12, 32(z)
+        mulpadd(%r14,%r13,32)
+        mulpadd(%r15,%r14,40)
+        mulpadd(%r8,%r15,48)
+        mulpade(%r9,%r8,56)
+        movq    32(x), %rdx
+        mulpade(%r10,%r9,40)
+        adcxq   zero, %r10
+
+        xorl    zeroe, zeroe
+        movq    16(x), %rdx
+        mulpadd(%r14,%r13,24)
+        movq    %r13, 40(z)
+        mulpadd(%r15,%r14,32)
+        movq    %r14, 48(z)
+        mulpadd(%r8,%r15,40)
+        mulpadd(%r9,%r8,48)
+        mulpadd(%r10,%r9,56)
+        movq    48(x), %rdx
+        mulpade(%r11,%r10,32)
+        mulpade(%r12,%r11,40)
+        adcxq   zero, %r12
+
+        xorl    zeroe, zeroe
+        movq    24(x), %rdx
+        mulpadd(%r8,%r15,32)
+        movq    %r15, 56(z)
+        mulpadd(%r9,%r8,40)
+        mulpadd(%r10,%r9,48)
+        mulpadd(%r11,%r10,56)
+        movq    56(x), %rdx
+        mulpadd(%r12,%r11,32)
+        mulpade(%r13,%r12,40)
+        mulpade(%r14,%r13,48)
+        adcxq   zero, %r14
+
+        xorl    zeroe, zeroe
+        movq    (x), %rdx
+        mulxq   %rdx, %rax, %rcx
+        movq    %rax, (z)
+        movq    8(z), %rax
+        adcxq   %rax, %rax
+        adoxq   %rcx, %rax
+        movq    %rax, 8(z)
+
+        movq    16(z), %rax
+        movq    8(x), %rdx
+        mulxq   %rdx, %rdx, %rcx
+        adcxq   %rax, %rax
+        adoxq   %rdx, %rax
+        movq    %rax, 16(z)
+        movq    24(z), %rax
+        adcxq   %rax, %rax
+        adoxq   %rcx, %rax
+        movq    %rax, 24(z)
+
+        movq    32(z), %rax
+        movq    16(x), %rdx
+        mulxq   %rdx, %rdx, %rcx
+        adcxq   %rax, %rax
+        adoxq   %rdx, %rax
+        movq    %rax, 32(z)
+        movq    40(z), %rax
+        adcxq   %rax, %rax
+        adoxq   %rcx, %rax
+        movq    %rax, 40(z)
+
+        movq    48(z), %rax
+        movq    24(x), %rdx
+        mulxq   %rdx, %rdx, %rcx
+        adcxq   %rax, %rax
+        adoxq   %rdx, %rax
+        movq    %rax, 48(z)
+        movq    56(z), %rax
+        adcxq   %rax, %rax
+        adoxq   %rcx, %rax
+        movq    %rax, 56(z)
+
+        movq    32(x), %rdx
+        mulxq   %rdx, %rdx, %rcx
+        adcxq   %r8, %r8
+        adoxq   %rdx, %r8
+        adcxq   %r9, %r9
+        adoxq   %rcx, %r9
+
+        movq    40(x), %rdx
+        mulxq   %rdx, %rdx, %rcx
+        adcxq   %r10, %r10
+        adoxq   %rdx, %r10
+        adcxq   %r11, %r11
+        adoxq   %rcx, %r11
+
+        movq    48(x), %rdx
+        mulxq   %rdx, %rdx, %rcx
+        adcxq   %r12, %r12
+        adoxq   %rdx, %r12
+        adcxq   %r13, %r13
+        adoxq   %rcx, %r13
+
+        movq    56(x), %rdx
+        mulxq   %rdx, %rdx, %r15
+        adcxq   %r14, %r14
+        adoxq   %rdx, %r14
+        adcxq   zero, %r15
+        adoxq   zero, %r15
+
+// Augment the high part with the contribution from the top little word C.
+// If we write the input as 2^512 * C + x then we are otherwise just doing
+// x^2, so we need to add to the high part 2^512 * C^2 + (2 * C) * x.
+// The initial doubling add of C also clears the CF and OF flags as desired.
+// We extend the window now to the 9-element %rbp,%r15,%r14,...,%r8.
+
+        movq    64(x), %rdx
+        movq    %rdx, %rbp
+        imulq   %rbp, %rbp
+        addq    %rdx, %rdx
+        mulpadd(%r9,%r8,0)
+        mulpadd(%r10,%r9,8)
+        mulpadd(%r11,%r10,16)
+        mulpadd(%r12,%r11,24)
+        mulpadd(%r13,%r12,32)
+        mulpadd(%r14,%r13,40)
+        mulpadd(%r15,%r14,48)
+        mulxq  56(x), %rax, %rcx
+        adcxq  %rax, %r15
+        adoxq  %rcx, %rbp
+        adcq   $0, %rbp
+
+// Rotate the upper portion right 9 bits since 2^512 == 2^-9 (mod p_521)
+// Let rotated result %rbp,%r15,%r14,...,%r8 be h (high) and z[0..7] be l (low)
+
+        movq    %r8, %rax
+        andq    $0x1FF, %rax
+        shrdq   $9, %r9, %r8
+        shrdq   $9, %r10, %r9
+        shrdq   $9, %r11, %r10
+        shrdq   $9, %r12, %r11
+        shrdq   $9, %r13, %r12
+        shrdq   $9, %r14, %r13
+        shrdq   $9, %r15, %r14
+        shrdq   $9, %rbp, %r15
+        shrq    $9, %rbp
+        addq    %rax, %rbp
+
+// Force carry-in then add to get s = h + l + 1
+// but actually add all 1s in the top 53 bits to get simple carry out
+
+        stc
+        adcq    (z), %r8
+        adcq    8(z), %r9
+        adcq    16(z), %r10
+        adcq    24(z), %r11
+        adcq    32(z), %r12
+        adcq    40(z), %r13
+        adcq    48(z), %r14
+        adcq    56(z), %r15
+        adcq    $~0x1FF, %rbp
+
+// Now CF is set <=> h + l + 1 >= 2^521 <=> h + l >= p_521,
+// in which case the lower 521 bits are already right. Otherwise if
+// CF is clear, we want to subtract 1. Hence suntract the complement
+// of the carry flag then mask the top word, which scrubs the
+// padding in either case. Write digits back as they are created.
+
+        cmc
+        sbbq    $0, %r8
+        movq    %r8, (z)
+        sbbq    $0, %r9
+        movq    %r9, 8(z)
+        sbbq    $0, %r10
+        movq    %r10, 16(z)
+        sbbq    $0, %r11
+        movq    %r11, 24(z)
+        sbbq    $0, %r12
+        movq    %r12, 32(z)
+        sbbq    $0, %r13
+        movq    %r13, 40(z)
+        sbbq    $0, %r14
+        movq    %r14, 48(z)
+        sbbq    $0, %r15
+        movq    %r15, 56(z)
+        sbbq    $0, %rbp
+        andq    $0x1FF, %rbp
+        movq    %rbp, 64(z)
+
+// Restore registers and return
+
+        popq    %r15
+        popq    %r14
+        popq    %r13
+        popq    %r12
+        popq    %rbp
+
+        ret
+
+#if defined(__linux__) && defined(__ELF__)
+.section .note.GNU-stack,"",%progbits
+#endif
diff --git a/x86_att/p521/bignum_sub_p521.S b/x86_att/p521/bignum_sub_p521.S
new file mode 100644
index 000000000..4988dd5f0
--- /dev/null
+++ b/x86_att/p521/bignum_sub_p521.S
@@ -0,0 +1,111 @@
+/*
+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License").
+ * You may not use this file except in compliance with the License.
+ * A copy of the License is located at
+ *
+ *  http://aws.amazon.com/apache2.0
+ *
+ * or in the "LICENSE" file accompanying this file. This file is distributed
+ * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
+ * express or implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ */
+
+// ----------------------------------------------------------------------------
+// Subtract modulo p_521, z := (x - y) mod p_521
+// Inputs x[9], y[9]; output z[9]
+//
+//    extern void bignum_sub_p521
+//     (uint64_t z[static 9], uint64_t x[static 9], uint64_t y[static 9]);
+//
+// Standard x86-64 ABI: RDI = z, RSI = x, RDX = y
+// ----------------------------------------------------------------------------
+
+
+        .globl  bignum_sub_p521
+        .text
+
+#define z %rdi
+#define x %rsi
+#define y %rdx
+
+#define d0 %rax
+#define d1 %rcx
+#define d2 %r8
+#define d3 %r9
+#define d4 %r10
+#define d5 %r11
+#define d6 %r12
+#define d7 %rbx
+
+// Re-use one input pointer as other variable once safe to do so
+
+#define d8 %rsi
+
+
+
+bignum_sub_p521:
+
+// Save more registers to play with
+
+        pushq   %rbx
+        pushq   %r12
+
+// First just subtract the numbers as [d8;d7;d6;d5;d4;d3;d2;d1;d0] = x - y
+
+        movq    (x), d0
+        subq    (y), d0
+        movq    8(x), d1
+        sbbq    8(y), d1
+        movq    16(x), d2
+        sbbq    16(y), d2
+        movq    24(x), d3
+        sbbq    24(y), d3
+        movq    32(x), d4
+        sbbq    32(y), d4
+        movq    40(x), d5
+        sbbq    40(y), d5
+        movq    48(x), d6
+        sbbq    48(y), d6
+        movq    56(x), d7
+        sbbq    56(y), d7
+        movq    64(x), d8
+        sbbq    64(y), d8
+
+// Now if x < y we want (x - y) + p_521 == (x - y) - 1 (mod 2^521)
+// Otherwise we just want the existing x - y result. So subtract
+// 1 iff the initial subtraction carried, then mask to 521 bits.
+// Write back the results as generated.
+
+        sbbq    $0, d0
+        movq    d0, (z)
+        sbbq    $0, d1
+        movq    d1, 8(z)
+        sbbq    $0, d2
+        movq    d2, 16(z)
+        sbbq    $0, d3
+        movq    d3, 24(z)
+        sbbq    $0, d4
+        movq    d4, 32(z)
+        sbbq    $0, d5
+        movq    d5, 40(z)
+        sbbq    $0, d6
+        movq    d6, 48(z)
+        sbbq    $0, d7
+        movq    d7, 56(z)
+        sbbq    $0, d8
+        andq    $0x1FF, d8
+        movq    d8, 64(z)
+
+// Restore registers and return
+
+        popq    %r12
+        popq    %rbx
+
+        ret
+
+#if defined(__linux__) && defined(__ELF__)
+.section .note.GNU-stack,"",%progbits
+#endif
diff --git a/x86_att/p521/bignum_triple_p521.S b/x86_att/p521/bignum_triple_p521.S
new file mode 100644
index 000000000..970cc78f8
--- /dev/null
+++ b/x86_att/p521/bignum_triple_p521.S
@@ -0,0 +1,154 @@
+/*
+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License").
+ * You may not use this file except in compliance with the License.
+ * A copy of the License is located at
+ *
+ *  http://aws.amazon.com/apache2.0
+ *
+ * or in the "LICENSE" file accompanying this file. This file is distributed
+ * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
+ * express or implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ */
+
+// ----------------------------------------------------------------------------
+// Triple modulo p_521, z := (3 * x) mod p_521, assuming x reduced
+// Input x[9]; output z[9]
+//
+//    extern void bignum_triple_p521
+//     (uint64_t z[static 9], uint64_t x[static 9]);
+//
+// Standard x86-64 ABI: RDI = z, RSI = x
+// ----------------------------------------------------------------------------
+
+
+        .globl  bignum_triple_p521
+        .text
+
+#define z %rdi
+#define x %rsi
+
+// d7 re-uses the input pointer when safe to do so
+
+#define d0 %rax
+#define d1 %rcx
+#define d2 %r8
+#define d3 %r9
+#define d4 %r10
+#define d5 %r11
+#define d6 %r12
+#define d7 %rsi
+#define d8 %rdx
+
+#define m %rbx
+#define mshort %ebx
+
+
+
+bignum_triple_p521:
+
+// Save more registers to play with
+
+                pushq   %rbx
+                pushq   %r12
+
+// Load the top (short) word first to compute the initial carry-in
+// Set OF according to bit 520, but *always* set CF to get a +1 bump
+
+                movq    64(x), m
+                movq    m, d8
+                shlq    $54, m
+                addq    m, m
+                stc
+
+// Use a double carry chain to compute x' + x + 1 where x' is a
+// 1-bit left rotation of x; this is then == 3 * x + 1 (mod p_521)
+// This gives us s = [d8;d7;d6;d5;d4;d3;d2;d1;d0] = x + x' + 1.
+
+                movq    (x), m
+                movq    m, d0
+                adcxq   m, m
+                adoxq   m, d0
+                movq    8(x), m
+                movq    m, d1
+                adcxq   m, m
+                adoxq   m, d1
+                movq    16(x), m
+                movq    m, d2
+                adcxq   m, m
+                adoxq   m, d2
+                movq    24(x), m
+                movq    m, d3
+                adcxq   m, m
+                adoxq   m, d3
+                movq    32(x), m
+                movq    m, d4
+                adcxq   m, m
+                adoxq   m, d4
+                movq    40(x), m
+                movq    m, d5
+                adcxq   m, m
+                adoxq   m, d5
+                movq    48(x), m
+                movq    m, d6
+                adcxq   m, m
+                adoxq   m, d6
+                movq    56(x), m
+                movq    m, d7
+                adcxq   m, m
+                adoxq   m, d7
+
+// The last word is slightly more intricate: we naturally end up adding
+// 2 * top bit when we shouldn't (because it's a rotation and we've already
+// added it at the LSB position) but then compensate by subtracting it.
+
+                movq    d8, m
+                adcxq   m, m
+                adoxq   m, d8
+                andq    $0x200, m
+                subq    m, d8
+
+// Now x + x' >= p_521 <=> s = x + x' + 1 >= 2^521
+// Make m = 512 * [x + x' >= p_521]
+
+                movl    $512, mshort
+                andq    d8, m
+
+// Now if x + x' >= p_521, we want (x + x') - p_521 = s - 2^521
+// while otherwise we want x + x' = s - 1
+// We use the mask m both as an operand and to generate the dual carry
+// Write back the results as generated
+
+                cmpq    $512, m
+
+                sbbq    $0, d0
+                movq    d0, (z)
+                sbbq    $0, d1
+                movq    d1, 8(z)
+                sbbq    $0, d2
+                movq    d2, 16(z)
+                sbbq    $0, d3
+                movq    d3, 24(z)
+                sbbq    $0, d4
+                movq    d4, 32(z)
+                sbbq    $0, d5
+                movq    d5, 40(z)
+                sbbq    $0, d6
+                movq    d6, 48(z)
+                sbbq    $0, d7
+                movq    d7, 56(z)
+                sbbq    m, d8
+                movq    d8, 64(z)
+
+// Restore registers and return
+
+                popq    %r12
+                popq    %rbx
+
+                ret
+
+#if defined(__linux__) && defined(__ELF__)
+.section .note.GNU-stack,"",%progbits
+#endif
